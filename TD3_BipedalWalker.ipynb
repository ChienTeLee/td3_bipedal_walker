{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TD3_BipedalWalker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dUoUiQ65FJ8",
        "colab_type": "text"
      },
      "source": [
        "# Twin-Delayed DDPG for Bipedal Walker\n",
        "\n",
        "The goal of this project is to implement Twin-Delayed DDPG (TD3) algorithm for BipedalWalker environment in OpenAi Gym. Twin-Delayed DDPG is an actor-critic framework which achieves state of the art performance for continuous control. While applying two critic networks, TD3 are able to select the smaller of the two predictions as the target q-value, and thus recude the over-estimation of the q-function. Next, TD3 delays the update of actor network to prevent policy function from varying too frequently. TD3 adds gaussian noise in action selection for action exploration during training, and the noise is clipped within boundaries. We also applies tricks such as target networks, huber loss, and soft update for stabilizing the training process.\n",
        "\n",
        "---\n",
        "The implementation is based on the following paper:\n",
        "- [Addressing Function Approximation Error in Actor-Critic Methods](https://arxiv.org/abs/1802.09477)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD5fCVoH5gZE",
        "colab_type": "text"
      },
      "source": [
        "### 1. prepare environment\n",
        "\n",
        "- Switch to tensorflow 2\n",
        "- Install dependencies\n",
        "- Import tensorflow, gym, matplotlib..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkuDRDfLSezF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tensorflow version 2\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lIzm4g74jNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "769b12f9-97bf-4eb5-8ba7-df62abe17e42"
      },
      "source": [
        "# install dependencies\n",
        "!pip install -q gym box2d-py pyvirtualdisplay\n",
        "!apt-get install -qq xvfb python-opengl ffmpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 450kB 8.6MB/s \n",
            "\u001b[?25hSelecting previously unselected package python-opengl.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhm6KnvRSxJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "import gym\n",
        "from gym import wrappers\n",
        "\n",
        "import glob\n",
        "import base64\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D6ygz_tSxLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "878d95a4-390a-4b07-f3f3-cc75df973cb0"
      },
      "source": [
        "# create display window for OpenAi gym\n",
        "display = Display(visible=0, size=(640, 480))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fec8c47ec50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd02XFa65rI-",
        "colab_type": "text"
      },
      "source": [
        "### 2. explore OpenAi Gym environment\n",
        "\n",
        "- The [BipedalWalker-v3](https://gym.openai.com/envs/BipedalWalker-v2/) environment is from [OpenAi Gym](https://gym.openai.com/)\n",
        "\n",
        "- The goal of this environment is to drive the Bipedal Walker to walk along the path witout falling down. This task is considered solved if the agent received average +300 reward within 1600 time step.\n",
        "\n",
        "- The 24 states represent:\n",
        "    - the x and y velocities\n",
        "    - the angle and angular velocities for the joints of hull, hips, kees, and legs\n",
        "    - ground_contact of legs\n",
        "    - 10 lidar readings for the distance to the ground\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/figure0.png\" width=\"50%\" height=\"50%\"> \n",
        "</p>\n",
        "\n",
        "- The 4 actions represent torque control of:\n",
        "    - Hip_1\n",
        "    - Knee_1\n",
        "    - Hip_2\n",
        "    - Knee_2\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/figure1.png\" width=\"50%\" height=\"50%\"> \n",
        "</p>\n",
        "\n",
        "- Moving forward receives total over +300 points to the far end. The robot recieves -100 points if it falls down. Applying torque to joints costs a small amount of points (around -0.02 points).\n",
        "\n",
        "- We first play the untrained Bipedal Walker for 5 times and record the simulation video in \"./before_train\". The simulation result looks like this:\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/before_train.gif\" width=\"50%\" height=\"50%\"> \n",
        "</p>\n",
        "- We cans see that the Bipedal Walker cannot land well on landing pad, and the average reward before training is around -100.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fgsWJp8HMfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3379c5a8-14fb-4340-9707-127ab5c475fb"
      },
      "source": [
        "# create OpenAi Gym environment\n",
        "env = gym.make(\"BipedalWalker-v3\")\n",
        "env = wrappers.Monitor(env, \"./before_train\", force=True, video_callable=lambda episode: (episode+1)>0)\n",
        "print(\"state space: \" + str(env.observation_space))\n",
        "print(\"action space: \" + str(env.action_space))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state space: Box(24,)\n",
            "action space: Box(4,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKC-tcPH5xWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d1c24f2-59a6-4773-b295-d7b55779e7bd"
      },
      "source": [
        "# play with untrained Bipedal Walker and record\n",
        "total_reward_history = []\n",
        "for i in range(5):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    while True:\n",
        "        action = env.action_space.sample()\n",
        "        state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            total_reward_history.append(total_reward)\n",
        "            break\n",
        "\n",
        "env.close()\n",
        "\n",
        "avg_reward = np.mean(total_reward_history)\n",
        "print(\"Average reward before training = {}\".format(avg_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average reward before training = -97.28602598899124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5JH93Yd5xac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_video(path):\n",
        "    \"\"\"\n",
        "    Display videos in the folder at colab notebook terminal.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the video folder. All videos in the folder will be played.\n",
        "        \n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    video_list = glob.glob(path + \"/*.mp4\")\n",
        "    html = []\n",
        "    for file in video_list:\n",
        "        video = open(file, 'rb').read()\n",
        "        base64_video = base64.b64encode(video).decode('ascii')\n",
        "        data_uri = \"data:video/mp4;base64,\" + base64_video\n",
        "        video_tag = '''\n",
        "        <video width=\"640\" height=\"480\" autoplay loop>\n",
        "            <source src={} type=\"video/mp4\">\n",
        "        </video>'''.format(data_uri)\n",
        "        html.append(video_tag)\n",
        "    html_tag = \"<br>\".join(html)\n",
        "    ipythondisplay.display(ipythondisplay.HTML(html_tag))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbvyHuMF5xc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_path = \"./before_train\"\n",
        "play_video(video_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQXL_nZR6BSk",
        "colab_type": "text"
      },
      "source": [
        "### 2. create Actor Critic network class\n",
        "\n",
        "- Here we create actor and critic networks for Twin-Delayed DDPG. The actor takes the state and predicts the action. The critic takes state and action to predict estimated q-value.\n",
        "\n",
        "- The network architecture is shown in the following diagram:\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/figure2.png\" width=\"55%\" height=\"55%\"> \n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq-B0snDS5if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Actor_Network(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    The keras model for actor network which takes state and output action.\n",
        "\n",
        "    Attributes:\n",
        "        dense_1 (tf.keras.layers.Dense) : First dense layer with relu activation.\n",
        "        dense_2 (tf.keras.layers.Dense) : Second dense layer with relu activation.\n",
        "        dense_3 (tf.keras.layers.Dense) : Third dense layer with tanh activation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_state, n_action, hidden_1=400, hidden_2=300):\n",
        "        \"\"\"\n",
        "        The __init__ method for Actor_Network class.\n",
        "\n",
        "        Args:\n",
        "            n_state (int): Number of states for input node.\n",
        "            n_action (int): Number of actions for output node.\n",
        "            hidden_1 (int): Number of hidden nodes for the first dense layer.\n",
        "            hidden_2 (int): Number of hidden nodes for the second dese layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dense_1 = tf.keras.layers.Dense(hidden_1, 'relu', name='dense_1')\n",
        "        self.dense_2 = tf.keras.layers.Dense(hidden_2, 'relu', name='dense_2')\n",
        "        self.dense_3 = tf.keras.layers.Dense(n_action, 'tanh', name='dense_3')\n",
        "\n",
        "        # build and call network\n",
        "        self.build((None, n_state))\n",
        "        inputs = tf.keras.Input(shape=n_state)\n",
        "        self.call(inputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        The call method for Actor_Network class.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): The state input to the network.\n",
        "        \n",
        "        Returns:\n",
        "            output (tf.Tensor): The action output of the network.\n",
        "        \"\"\"\n",
        "        dense_1_out = self.dense_1(inputs)\n",
        "        dense_2_out = self.dense_2(dense_1_out)\n",
        "        output = self.dense_3(dense_2_out)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71zZ9JJaS5pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic_Network(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    The keras model for critic network which takes state, action and outputs estimated q-value.\n",
        "\n",
        "    Attributes:\n",
        "        dense_1 (tf.keras.layers.Dense) : First dense layer with relu activation.\n",
        "        dense_2 (tf.keras.layers.Dense) : Second dense layer with relu activation.\n",
        "        dense_3 (tf.keras.layers.Dense) : Third dense layer with linear activation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_state, n_action, hidden_1=400, hidden_2=300):\n",
        "        \"\"\"\n",
        "        The __init__ method for Critic_Network class.\n",
        "\n",
        "        Args:\n",
        "            n_state (int): Number of states for input node.\n",
        "            n_action (int): Number of actions for output node.\n",
        "            hidden_1 (int): Number of hidden nodes for the first dense layer.\n",
        "            hidden_2 (int): Number of hidden nodes for the second dese layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dense_1 = tf.keras.layers.Dense(hidden_1, 'relu', name='dense_1')\n",
        "        self.dense_2 = tf.keras.layers.Dense(hidden_2, 'relu', name='dense_2')\n",
        "        self.dense_3 = tf.keras.layers.Dense(1, 'linear', name='dense_3')\n",
        "\n",
        "        # build and call network\n",
        "        self.build([(None, n_state), (None, n_action)])\n",
        "        state= tf.keras.Input(shape=n_state)\n",
        "        action= tf.keras.Input(shape=n_action)\n",
        "        self.call([state, action])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        The call method for Critic_Network class.\n",
        "\n",
        "        Args:\n",
        "            inputs (list:tf.Tensor): list of tensor containing [state, action]\n",
        "        \n",
        "        Returns:\n",
        "            output (tf.Tensor): The q-value output of the network.\n",
        "        \"\"\"\n",
        "        # input x must be a list of [state, action]\n",
        "        state = inputs[0]\n",
        "        action = inputs[1]\n",
        "        concat = tf.concat([state, action], axis=1)\n",
        "        dense_1_out = self.dense_1(concat)\n",
        "        dense_2_out = self.dense_2(dense_1_out)\n",
        "        output = self.dense_3(dense_2_out)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1LzUsOT8_LY",
        "colab_type": "text"
      },
      "source": [
        "### 3. create replay memory class\n",
        "\n",
        "- The experinces (state, action, reward, next_state, done) are stored in rotation numpy arrays.\n",
        "\n",
        "- It performs uniform random sampling to select minibatch for experience replay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA5M2PP-SxSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Replay_Memory(object):\n",
        "    \"\"\"\n",
        "    The Replay_Memory class. The experiences (state, action, reward, next_state, done) are stored in\n",
        "    rotation numpy arrays.\n",
        "\n",
        "    Attributes:\n",
        "        capacity (int): Maximun capacity of the memory.\n",
        "        batch_size (int): The batch size for sampling experiences.\n",
        "        n_sample (int): Indicates how many samples has entered the memory from the beginning of time.\n",
        "        state_mem (ndarray:float): States stored in numpy array.\n",
        "        action_mem (ndarray:int): Actions stored in numpy array.\n",
        "        reward_mem (ndarray:float): Rewards stored in numpy array.\n",
        "        next_state_mem (ndarray:float): Next states stored in numpy array.\n",
        "        done_mem (ndarray:float): Terminals stored in numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, capacity, n_state, n_action, batch_size):\n",
        "        \"\"\"\n",
        "        The __init__ method for Replay_Memory class.\n",
        "\n",
        "        Args:\n",
        "            capacity (int): Maximun capacity of the memory\n",
        "            n_state (int): Number of states.\n",
        "            n_action (int): Number of actions.\n",
        "            batch_size (int): The batch size for sampling experiences.\n",
        "        \"\"\"\n",
        "        # set parameters\n",
        "        self.capacity = capacity\n",
        "        self.batch_size = batch_size\n",
        "        self.n_sample = 0\n",
        "\n",
        "        # store memory in rotation np array\n",
        "        self.state_mem = np.zeros((capacity, n_state), dtype=np.float32)\n",
        "        self.action_mem = np.zeros((capacity, n_action), dtype=np.float32)\n",
        "        self.reward_mem = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.next_state_mem = np.zeros((capacity, n_state), dtype=np.float32)\n",
        "        self.done_mem = np.zeros((capacity, 1), dtype=np.float32)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"\n",
        "        Store current experience (state, action, reward, next_state, done) in memory.\n",
        "\n",
        "        Args:\n",
        "            state (ndarray:float): Current state of agent.\n",
        "            action (ndarray:float): Executed action.\n",
        "            reward (float): The reward when taking action in state.\n",
        "            next_state (ndarray:float): Next state of agent.\n",
        "            done (float): 1 indicates terminal state, and 0 indicates non-terminal state.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # store one transition in memory\n",
        "        index = self.n_sample % self.capacity\n",
        "        self.state_mem[index] = state\n",
        "        self.action_mem[index] = action\n",
        "        self.reward_mem[index] = reward\n",
        "        self.next_state_mem[index] = next_state\n",
        "        self.done_mem[index] = done\n",
        "        # increase memory count\n",
        "        self.n_sample = self.n_sample + 1\n",
        "    \n",
        "    def get_minibatch(self):\n",
        "        \"\"\"\n",
        "        Random get minibatch samples.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            (tuple): tuple containing:\n",
        "                 states (ndarray:float): Sampled states corresponding to indicies.\n",
        "                 actions (ndarray:float): Sampled actions corresponding to indicies.\n",
        "                 rewards (ndarray:float): Sampled rewards corresponding to indicies.\n",
        "                 next_states (ndarray:float): Sampled next_states corresponding to indicies.\n",
        "                 dones (ndarray:float): Sampled dones corresponding to indicies.\n",
        "        \"\"\"\n",
        "        # random sample minibatch\n",
        "        index = np.random.choice(min(self.n_sample, self.capacity), size=self.batch_size, replace=False)\n",
        "        return self.state_mem[index], self.action_mem[index], self.reward_mem[index], \\\n",
        "                self.next_state_mem[index], self.done_mem[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEFzKO8j9CBW",
        "colab_type": "text"
      },
      "source": [
        "### 4. create TD3 agent class\n",
        "\n",
        "- Combine the above actor network, critic network and replay memory, we are able to create a TD3_Agent class. The agent is implemnted with the training algorithm based on the following pseudocode:\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/figure3.png\" width=\"80%\" height=\"80%\"> \n",
        "</p>\n",
        "\n",
        "- The data flow is shown in the following diagram:\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/figure4.png\" width=\"80%\" height=\"80%\"> \n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHs8grkZP7gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TD3_Agent(object):\n",
        "    \"\"\"\n",
        "    The class of Twin-Delayed DDPG agent.\n",
        "\n",
        "    Attributes:\n",
        "        n_state (int): Number of states.\n",
        "        n_action (int): Number of actions.\n",
        "        batch_size (int): The batch size for sampling experiences.\n",
        "        learning_rate (float): Learning rate for updating network.\n",
        "        gamma (float): Reward decay.\n",
        "        tau (float): Interpolation parameter for soft update.\n",
        "        delay_interval (float): Delay interval for policy update.\n",
        "        std_dev (float): Standard deviation for gaussian noise\n",
        "        c (float): gaussian noise boundary\n",
        "        memory_len (int): Size of memory.\n",
        "        memory (Replay_Memory): Replay memory for sampling experiences.\n",
        "\n",
        "        actor_net (Actor_Network): actor network.\n",
        "        actor_target_net (Actor_Network): target actor network.\n",
        "        critic_net_1 (Critic_Network): critic network 1.\n",
        "        critic_target_net_1 (Critic_Network): target critic network 1.\n",
        "        critic_net_2 (Critic_Network): critic network 2.\n",
        "        critic_target_net_2 (Critic_Network): target critic network 2.\n",
        "\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Adam optimizer.\n",
        "        loss_fn (tf.keras.losses): Huber loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_state, n_action, batch_size=128, learning_rate=0.0005,  gamma=0.99, tau=0.005, \\\n",
        "                 delay_interval=10, std_dev=0.1, c=0.3, memory_len=40000):\n",
        "        \"\"\"\n",
        "        The __init__ method for TD3_Agent class.\n",
        "\n",
        "        Args:\n",
        "            n_state (int): Number of states.\n",
        "            n_action (int): Number of actions.\n",
        "            batch_size (int): The batch size for sampling experiences.\n",
        "            learning_rate (float): Learning rate for updating network.\n",
        "            gamma (float): Reward decay.\n",
        "            tau (float): Interpolation parameter for soft update.\n",
        "            delay_interval (float): Delay interval for policy update.\n",
        "            std_dev (float): Standard deviation for gaussian noise\n",
        "            c (float): gaussian noise boundary\n",
        "            memory_len (int): Size of memory.\n",
        "        \"\"\"\n",
        "        # set parameters\n",
        "        self.n_state = n_state\n",
        "        self.n_action = n_action\n",
        "        self.batch_size = batch_size\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.delay_interval = delay_interval\n",
        "        self.std_dev = std_dev\n",
        "        self.c = c\n",
        "\n",
        "        # create memory\n",
        "        self.memory = Replay_Memory(memory_len, n_state, n_action, batch_size)\n",
        "\n",
        "        # create actor evaluate and target nets\n",
        "        self.actor_net = Actor_Network(n_state, n_action)\n",
        "        self.actor_target_net = Actor_Network(n_state, n_action)\n",
        "\n",
        "        # critic 1 evaluate and target nets\n",
        "        self.critic_net_1 = Critic_Network(n_state, n_action)\n",
        "        self.critic_target_net_1 = Critic_Network(n_state, n_action)\n",
        "\n",
        "        # critic 2 evaluate and target networks\n",
        "        self.critic_net_2 = Critic_Network(n_state, n_action)\n",
        "        self.critic_target_net_2 = Critic_Network(n_state, n_action)\n",
        "\n",
        "        # set weights for target nets\n",
        "        self.actor_target_net.set_weights(self.actor_net.get_weights())\n",
        "        self.critic_target_net_1.set_weights(self.critic_net_1.get_weights())\n",
        "        self.critic_target_net_2.set_weights(self.critic_net_2.get_weights())\n",
        "        self.actor_target_net.trainable = False\n",
        "        self.critic_target_net_1.trainable = False\n",
        "        self.critic_target_net_2.trainable = False\n",
        "\n",
        "        # create huber loss function and optimizer\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    @tf.function\n",
        "    def choose_noise_action(self, state):\n",
        "        \"\"\"\n",
        "        Choose action using output of policy net with gaussian noise.\n",
        "\n",
        "        Args:\n",
        "            state (ndarray:float): Current state of agent.\n",
        "\n",
        "        Returns:\n",
        "            action (ndarray:float): The selected action.\n",
        "        \"\"\"\n",
        "        noise = tf.random.normal(shape = (1, self.n_action), mean=0.0, stddev=self.std_dev)\n",
        "        action = self.actor_net(state[None,:]) + tf.clip_by_value(noise, -1.0*self.c, self.c)\n",
        "        return action[0]\n",
        "    \n",
        "    @tf.function\n",
        "    def choose_greedy_action(self, state):\n",
        "        \"\"\"\n",
        "        Choose greedy action using output of policy net.\n",
        "\n",
        "        Args:\n",
        "            state (ndarray:float): Current state of agent.\n",
        "\n",
        "        Returns:\n",
        "            action (ndarray:float): The selected action.\n",
        "        \"\"\"\n",
        "        action = self.actor_net(state[None,:])\n",
        "        return action[0]\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        \"\"\"\n",
        "        Store one experience (state, action, reward, next_state, done) in memory.\n",
        "\n",
        "        Args:\n",
        "            state (ndarray:float): Current state of agent.\n",
        "            action (ndarray:float): Executed action.\n",
        "            reward (float): The reward when taking action in state.\n",
        "            next_state (ndarray:float): Next state of agent.\n",
        "            done (float): 1 indicates terminal state, and 0 indicates non-terminal state.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "    def experience_replay(self, time):\n",
        "        \"\"\"\n",
        "        Random sample minibatch experiences and train actor and critic networks. After that, update \n",
        "        target network weights.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        if self.memory.n_sample < self.batch_size:\n",
        "            return\n",
        "\n",
        "        states, actions, rewards, next_states, dones = self.memory.get_minibatch()\n",
        "        self.train_critic(states, actions, rewards, next_states, dones)\n",
        "        if time % self.delay_interval == 0:\n",
        "          self.train_actor(states)\n",
        "          self.soft_update_network(self.actor_net, self.actor_target_net)\n",
        "          self.soft_update_network(self.critic_net_1, self.critic_target_net_1)\n",
        "          self.soft_update_network(self.critic_net_2, self.critic_target_net_2)\n",
        "\n",
        "    @tf.function\n",
        "    def train_critic(self, states, actions, rewards, next_states, dones):\n",
        "        \"\"\"\n",
        "        Train step for training critic netowrk 1 and 2. Calculate next_actions and targets y. Perform \n",
        "        gradient descent for critic netowrk 1 and 2 respectively\n",
        "\n",
        "        Args:\n",
        "            states (ndarray:float): Sampled minibatch states.\n",
        "            actions (ndarray:float): Sampled minibatch actions.\n",
        "            rewards (ndarray:float): Sampled minibatch rewards.\n",
        "            next_states (ndarray:float): Sampled minibatch next_states.\n",
        "            dones (ndarray:float): Sampled minibatch dones.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        noise = tf.random.normal([self.batch_size, self.n_action], mean=0.0, stddev=self.std_dev)\n",
        "        next_actions = self.actor_target_net(next_states) + tf.clip_by_value(noise, -1.0*self.c, self.c)\n",
        "\n",
        "        next_q_values_1 = self.critic_target_net_1([next_states, next_actions])\n",
        "        next_q_values_2 = self.critic_target_net_2([next_states, next_actions])\n",
        "        y = rewards + (1-dones) * self.gamma * tf.math.minimum(next_q_values_1, next_q_values_2)\n",
        "\n",
        "        # train critic network 1\n",
        "        with tf.GradientTape() as tape:\n",
        "            q_1 = self.critic_net_1([states, actions])\n",
        "            loss = self.loss_fn(y, q_1)\n",
        "        gradients = tape.gradient(loss, self.critic_net_1.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.critic_net_1.trainable_variables))\n",
        "\n",
        "        # train critic network 2\n",
        "        with tf.GradientTape() as tape:\n",
        "            q_2 = self.critic_net_2([states, actions])\n",
        "            loss = self.loss_fn(y, q_2)\n",
        "        gradients = tape.gradient(loss, self.critic_net_2.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.critic_net_2.trainable_variables))\n",
        "\n",
        "    @tf.function\n",
        "    def train_actor(self, states):\n",
        "        \"\"\"\n",
        "        Train step for training actor netowrk.\n",
        "\n",
        "        Args:\n",
        "            states (ndarray:float): Sampled minibatch states.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        #  train actor network\n",
        "        with tf.GradientTape() as tape:\n",
        "            actions = self.actor_net(states)\n",
        "            q = self.critic_net_1([states, actions])\n",
        "            loss = -tf.reduce_mean(q)\n",
        "        gradients = tape.gradient(loss, self.actor_net.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.actor_net.trainable_variables))\n",
        "\n",
        "    def soft_update_network(self, evaluate_net, target_net):\n",
        "        \"\"\"\n",
        "        Soft update weights target network. target =  tau * evaluate + (1 - tau) * target.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        evaluate_weight = evaluate_net.get_weights()\n",
        "        target_weight = target_net.get_weights()\n",
        "        for i in range(len(evaluate_weight)):\n",
        "            target_weight[i] = self.tau * evaluate_weight[i] + (1 - self.tau) * target_weight[i]\n",
        "        target_net.set_weights(target_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5yrM3_XJUON",
        "colab_type": "text"
      },
      "source": [
        "### 5. train the TD3 agent\n",
        "\n",
        "- Create OpenAI Gym \"BipedalWalker-v3\" environment\n",
        "\n",
        "- Create Twin-Delayed DDPG agent\n",
        "\n",
        "- View the training process and plot the training curve.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMyq-05PP7jK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "489d98fa-ca24-4074-80bc-8321178b08ff"
      },
      "source": [
        "# create environment and agent\n",
        "env = gym.make(\"BipedalWalker-v3\")\n",
        "env = wrappers.Monitor(env, \"./during_train\", force=True, video_callable=lambda episode: (episode+1)%25==0)\n",
        "\n",
        "n_state = env.observation_space.shape[0]\n",
        "n_action = env.action_space.shape[0]\n",
        "td3_agent = TD3_Agent(n_state, n_action)\n",
        "\n",
        "# view network summary\n",
        "td3_agent.actor_net.summary()\n",
        "print(\"\\n\")\n",
        "td3_agent.critic_net_1.summary()\n",
        "print(\"\\n\")\n",
        "td3_agent.critic_net_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"actor__network\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 400)               10000     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 300)               120300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 1204      \n",
            "=================================================================\n",
            "Total params: 131,504\n",
            "Trainable params: 131,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model: \"critic__network\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 400)               11600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 300)               120300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 132,201\n",
            "Trainable params: 132,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model: \"critic__network_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 400)               11600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 300)               120300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 132,201\n",
            "Trainable params: 132,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liqXUOsgP7lT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a10e8791-e964-4ff5-8829-130650235d0a"
      },
      "source": [
        "# inititalize parameters\n",
        "N_EPISODE = 2500\n",
        "random_time = 10000\n",
        "time = 0\n",
        "solved = False\n",
        "\n",
        "reward_window = deque(maxlen=50)\n",
        "total_reward_history = []\n",
        "avg_reward_history = []\n",
        "\n",
        "# start training loop\n",
        "print(\"Start Training\")\n",
        "for episode in range(N_EPISODE):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = 0\n",
        "\n",
        "    while not done:\n",
        "        time += 1\n",
        "        # take random action if time < random_time , else take greedy action\n",
        "        if time < random_time:\n",
        "                action = env.action_space.sample()\n",
        "        else:\n",
        "            action = td3_agent.choose_noise_action(state)\n",
        "\n",
        "        # take action in environment\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        \n",
        "        # store transition\n",
        "        td3_agent.store_transition(state, action, reward, next_state, done)\n",
        "\n",
        "        # experience replay\n",
        "        td3_agent.experience_replay(time)\n",
        "\n",
        "        # move on to next state\n",
        "        state = next_state\n",
        "\n",
        "    # record training history\n",
        "    total_reward_history.append(total_reward)\n",
        "    reward_window.append(total_reward)\n",
        "    avg_reward = np.mean(reward_window)\n",
        "    avg_reward_history.append(avg_reward)\n",
        "\n",
        "    template = \"episode={:d}/{:d}, total_reward={:.4f}, avg_reward={:.4f}, time={:d}\"\n",
        "    print(template.format(episode, N_EPISODE, total_reward, avg_reward, time))\n",
        "    \n",
        "    # break the loop if problem solved\n",
        "    if episode >= 50 and avg_reward >= 300:\n",
        "        solved = True\n",
        "        print(\"Solved at\", episode, \"episode!\")\n",
        "        break\n",
        "\n",
        "if not solved:\n",
        "    print (\"Not solve the problem yet!\")\n",
        "    \n",
        "print(\"Average reward = %d \" % avg_reward)\n",
        "print (\"End Training \\n\")\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "episode=0/2500, total_reward=-119.0217, avg_reward=-119.0217, time=65\n",
            "episode=1/2500, total_reward=-98.0601, avg_reward=-108.5409, time=142\n",
            "episode=2/2500, total_reward=-102.8812, avg_reward=-106.6544, time=192\n",
            "episode=3/2500, total_reward=-78.5565, avg_reward=-99.6299, time=1792\n",
            "episode=4/2500, total_reward=-81.0315, avg_reward=-95.9102, time=3392\n",
            "episode=5/2500, total_reward=-114.6385, avg_reward=-99.0316, time=3448\n",
            "episode=6/2500, total_reward=-84.2010, avg_reward=-96.9129, time=5048\n",
            "episode=7/2500, total_reward=-102.0693, avg_reward=-97.5575, time=5104\n",
            "episode=8/2500, total_reward=-89.1603, avg_reward=-96.6245, time=6704\n",
            "episode=9/2500, total_reward=-100.6246, avg_reward=-97.0245, time=6789\n",
            "episode=10/2500, total_reward=-83.4908, avg_reward=-95.7941, time=8389\n",
            "episode=11/2500, total_reward=-99.0935, avg_reward=-96.0691, time=8456\n",
            "episode=12/2500, total_reward=-124.0121, avg_reward=-98.2186, time=8547\n",
            "WARNING:tensorflow:Layer actor__network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "episode=13/2500, total_reward=-80.2447, avg_reward=-96.9347, time=10147\n",
            "episode=14/2500, total_reward=-87.8245, avg_reward=-96.3274, time=11747\n",
            "episode=15/2500, total_reward=-133.4179, avg_reward=-98.6455, time=11886\n",
            "episode=16/2500, total_reward=-119.1355, avg_reward=-99.8508, time=12001\n",
            "episode=17/2500, total_reward=-130.7799, avg_reward=-101.5691, time=12294\n",
            "episode=18/2500, total_reward=-122.8526, avg_reward=-102.6893, time=12358\n",
            "episode=19/2500, total_reward=-121.6801, avg_reward=-103.6388, time=12420\n",
            "episode=20/2500, total_reward=-123.1537, avg_reward=-104.5681, time=12477\n",
            "episode=21/2500, total_reward=-88.3891, avg_reward=-103.8327, time=14077\n",
            "episode=22/2500, total_reward=-55.4108, avg_reward=-101.7274, time=15677\n",
            "episode=23/2500, total_reward=-63.8163, avg_reward=-100.1478, time=17277\n",
            "episode=24/2500, total_reward=-51.5859, avg_reward=-98.2053, time=18877\n",
            "episode=25/2500, total_reward=-78.6325, avg_reward=-97.4525, time=20477\n",
            "episode=26/2500, total_reward=-102.9166, avg_reward=-97.6549, time=20632\n",
            "episode=27/2500, total_reward=-81.8198, avg_reward=-97.0893, time=22232\n",
            "episode=28/2500, total_reward=-64.4023, avg_reward=-95.9622, time=23832\n",
            "episode=29/2500, total_reward=-52.2143, avg_reward=-94.5039, time=25432\n",
            "episode=30/2500, total_reward=-132.5772, avg_reward=-95.7321, time=26489\n",
            "episode=31/2500, total_reward=-44.8718, avg_reward=-94.1427, time=28089\n",
            "episode=32/2500, total_reward=-48.1140, avg_reward=-92.7479, time=29689\n",
            "episode=33/2500, total_reward=-92.4501, avg_reward=-92.7391, time=29785\n",
            "episode=34/2500, total_reward=-111.6610, avg_reward=-93.2798, time=30259\n",
            "episode=35/2500, total_reward=-87.9589, avg_reward=-93.1320, time=31859\n",
            "episode=36/2500, total_reward=-71.9643, avg_reward=-92.5599, time=33459\n",
            "episode=37/2500, total_reward=-74.1693, avg_reward=-92.0759, time=35059\n",
            "episode=38/2500, total_reward=-62.5366, avg_reward=-91.3185, time=36659\n",
            "episode=39/2500, total_reward=-101.0835, avg_reward=-91.5626, time=36715\n",
            "episode=40/2500, total_reward=-99.7782, avg_reward=-91.7630, time=36772\n",
            "episode=41/2500, total_reward=-98.8399, avg_reward=-91.9315, time=36832\n",
            "episode=42/2500, total_reward=-100.7584, avg_reward=-92.1368, time=36886\n",
            "episode=43/2500, total_reward=-102.4564, avg_reward=-92.3713, time=36946\n",
            "episode=44/2500, total_reward=-51.3229, avg_reward=-91.4591, time=38546\n",
            "episode=45/2500, total_reward=-102.3507, avg_reward=-91.6959, time=38609\n",
            "episode=46/2500, total_reward=-100.2860, avg_reward=-91.8787, time=38676\n",
            "episode=47/2500, total_reward=-101.1948, avg_reward=-92.0727, time=38754\n",
            "episode=48/2500, total_reward=-100.5786, avg_reward=-92.2463, time=38812\n",
            "episode=49/2500, total_reward=-101.7829, avg_reward=-92.4371, time=38869\n",
            "episode=50/2500, total_reward=-101.1306, avg_reward=-92.0792, time=38920\n",
            "episode=51/2500, total_reward=-100.5791, avg_reward=-92.1296, time=38965\n",
            "episode=52/2500, total_reward=-100.7889, avg_reward=-92.0878, time=39022\n",
            "episode=53/2500, total_reward=-99.3761, avg_reward=-92.5042, time=39103\n",
            "episode=54/2500, total_reward=-51.7275, avg_reward=-91.9181, time=40703\n",
            "episode=55/2500, total_reward=-104.2314, avg_reward=-91.7099, time=40756\n",
            "episode=56/2500, total_reward=-104.5189, avg_reward=-92.1163, time=40807\n",
            "episode=57/2500, total_reward=-101.9254, avg_reward=-92.1134, time=40845\n",
            "episode=58/2500, total_reward=-104.7371, avg_reward=-92.4250, time=40897\n",
            "episode=59/2500, total_reward=-102.0794, avg_reward=-92.4541, time=40945\n",
            "episode=60/2500, total_reward=-101.2588, avg_reward=-92.8094, time=40991\n",
            "episode=61/2500, total_reward=-100.9251, avg_reward=-92.8460, time=41032\n",
            "episode=62/2500, total_reward=-101.8749, avg_reward=-92.4033, time=41128\n",
            "episode=63/2500, total_reward=-102.4589, avg_reward=-92.8476, time=41177\n",
            "episode=64/2500, total_reward=-52.2644, avg_reward=-92.1364, time=42777\n",
            "episode=65/2500, total_reward=-106.1297, avg_reward=-91.5906, time=42837\n",
            "episode=66/2500, total_reward=-105.8636, avg_reward=-91.3252, time=42888\n",
            "episode=67/2500, total_reward=-104.8252, avg_reward=-90.8061, time=42943\n",
            "episode=68/2500, total_reward=-102.2152, avg_reward=-90.3933, time=43005\n",
            "episode=69/2500, total_reward=-103.9554, avg_reward=-90.0388, time=43061\n",
            "episode=70/2500, total_reward=-99.9197, avg_reward=-89.5742, time=43143\n",
            "episode=71/2500, total_reward=-102.6553, avg_reward=-89.8595, time=43239\n",
            "episode=72/2500, total_reward=-103.6962, avg_reward=-90.8252, time=43302\n",
            "episode=73/2500, total_reward=-104.9945, avg_reward=-91.6488, time=43375\n",
            "episode=74/2500, total_reward=-105.8914, avg_reward=-92.7349, time=43454\n",
            "episode=75/2500, total_reward=-103.2688, avg_reward=-93.2276, time=43518\n",
            "episode=76/2500, total_reward=-102.3060, avg_reward=-93.2154, time=43598\n",
            "episode=77/2500, total_reward=-101.9475, avg_reward=-93.6179, time=43687\n",
            "episode=78/2500, total_reward=-110.9516, avg_reward=-94.5489, time=43750\n",
            "episode=79/2500, total_reward=-110.2441, avg_reward=-95.7095, time=43824\n",
            "episode=80/2500, total_reward=-110.3645, avg_reward=-95.2653, time=43897\n",
            "episode=81/2500, total_reward=-104.5437, avg_reward=-96.4587, time=43975\n",
            "episode=82/2500, total_reward=-106.0099, avg_reward=-97.6166, time=44069\n",
            "episode=83/2500, total_reward=-105.9287, avg_reward=-97.8862, time=44207\n",
            "episode=84/2500, total_reward=-107.4935, avg_reward=-97.8029, time=44280\n",
            "episode=85/2500, total_reward=-102.8352, avg_reward=-98.1004, time=44379\n",
            "episode=86/2500, total_reward=-104.8841, avg_reward=-98.7588, time=44505\n",
            "episode=87/2500, total_reward=-102.6258, avg_reward=-99.3279, time=44595\n",
            "episode=88/2500, total_reward=-108.5842, avg_reward=-100.2489, time=44782\n",
            "episode=89/2500, total_reward=-111.5961, avg_reward=-100.4591, time=44854\n",
            "episode=90/2500, total_reward=-104.2692, avg_reward=-100.5489, time=44935\n",
            "episode=91/2500, total_reward=-106.4490, avg_reward=-100.7011, time=44999\n",
            "episode=92/2500, total_reward=-102.1706, avg_reward=-100.7293, time=45084\n",
            "episode=93/2500, total_reward=-101.4436, avg_reward=-100.7091, time=45171\n",
            "episode=94/2500, total_reward=-103.8336, avg_reward=-101.7593, time=45217\n",
            "episode=95/2500, total_reward=-102.6612, avg_reward=-101.7655, time=45298\n",
            "episode=96/2500, total_reward=-103.6895, avg_reward=-101.8336, time=45375\n",
            "episode=97/2500, total_reward=-108.3293, avg_reward=-101.9763, time=45428\n",
            "episode=98/2500, total_reward=-108.2447, avg_reward=-102.1296, time=45482\n",
            "episode=99/2500, total_reward=-106.2997, avg_reward=-102.2199, time=45535\n",
            "episode=100/2500, total_reward=-105.6235, avg_reward=-102.3098, time=45586\n",
            "episode=101/2500, total_reward=-106.2090, avg_reward=-102.4224, time=45635\n",
            "episode=102/2500, total_reward=-105.5824, avg_reward=-102.5183, time=45681\n",
            "episode=103/2500, total_reward=-109.1952, avg_reward=-102.7146, time=45735\n",
            "episode=104/2500, total_reward=-106.9052, avg_reward=-103.8182, time=45783\n",
            "episode=105/2500, total_reward=-106.4442, avg_reward=-103.8625, time=45829\n",
            "episode=106/2500, total_reward=-106.7252, avg_reward=-103.9066, time=45882\n",
            "episode=107/2500, total_reward=-107.8358, avg_reward=-104.0248, time=45936\n",
            "episode=108/2500, total_reward=-106.2404, avg_reward=-104.0549, time=45988\n",
            "episode=109/2500, total_reward=-103.2716, avg_reward=-104.0787, time=46040\n",
            "episode=110/2500, total_reward=-109.0883, avg_reward=-104.2353, time=46099\n",
            "episode=111/2500, total_reward=-104.0274, avg_reward=-104.2973, time=46173\n",
            "episode=112/2500, total_reward=-100.1631, avg_reward=-104.2631, time=46276\n",
            "episode=113/2500, total_reward=-105.1192, avg_reward=-104.3163, time=46329\n",
            "episode=114/2500, total_reward=-105.2842, avg_reward=-105.3767, time=46380\n",
            "episode=115/2500, total_reward=-99.6357, avg_reward=-105.2468, time=46464\n",
            "episode=116/2500, total_reward=-99.9595, avg_reward=-105.1287, time=46528\n",
            "episode=117/2500, total_reward=-105.9788, avg_reward=-105.1518, time=46597\n",
            "episode=118/2500, total_reward=-99.1826, avg_reward=-105.0912, time=46687\n",
            "episode=119/2500, total_reward=-104.8998, avg_reward=-105.1100, time=46737\n",
            "episode=120/2500, total_reward=-104.4113, avg_reward=-105.1999, time=46792\n",
            "episode=121/2500, total_reward=-102.7052, avg_reward=-105.2009, time=46851\n",
            "episode=122/2500, total_reward=-107.9299, avg_reward=-105.2856, time=46921\n",
            "episode=123/2500, total_reward=-101.4588, avg_reward=-105.2148, time=46975\n",
            "episode=124/2500, total_reward=-106.5019, avg_reward=-105.2270, time=47019\n",
            "episode=125/2500, total_reward=-111.0168, avg_reward=-105.3820, time=48619\n",
            "episode=126/2500, total_reward=-101.2537, avg_reward=-105.3610, time=48672\n",
            "episode=127/2500, total_reward=-101.9155, avg_reward=-105.3603, time=48729\n",
            "episode=128/2500, total_reward=-100.6653, avg_reward=-105.1546, time=48782\n",
            "episode=129/2500, total_reward=-101.7592, avg_reward=-104.9849, time=48833\n",
            "episode=130/2500, total_reward=-103.3270, avg_reward=-104.8441, time=48893\n",
            "episode=131/2500, total_reward=-105.7661, avg_reward=-104.8686, time=48953\n",
            "episode=132/2500, total_reward=-100.9669, avg_reward=-104.7677, time=49010\n",
            "episode=133/2500, total_reward=-100.0527, avg_reward=-104.6502, time=49070\n",
            "episode=134/2500, total_reward=-101.1942, avg_reward=-104.5242, time=49131\n",
            "episode=135/2500, total_reward=-100.8962, avg_reward=-104.4854, time=49188\n",
            "episode=136/2500, total_reward=-101.6634, avg_reward=-104.4210, time=49239\n",
            "episode=137/2500, total_reward=-100.9426, avg_reward=-104.3874, time=49293\n",
            "episode=138/2500, total_reward=-103.3032, avg_reward=-104.2818, time=49363\n",
            "episode=139/2500, total_reward=-101.1364, avg_reward=-104.0726, time=49430\n",
            "episode=140/2500, total_reward=-102.3977, avg_reward=-104.0351, time=49494\n",
            "episode=141/2500, total_reward=-102.4372, avg_reward=-103.9549, time=49562\n",
            "episode=142/2500, total_reward=-101.1922, avg_reward=-103.9353, time=49617\n",
            "episode=143/2500, total_reward=-102.0248, avg_reward=-103.9469, time=49675\n",
            "episode=144/2500, total_reward=-100.9342, avg_reward=-103.8890, time=49748\n",
            "episode=145/2500, total_reward=-101.3180, avg_reward=-103.8621, time=49805\n",
            "episode=146/2500, total_reward=-100.3710, avg_reward=-103.7957, time=49865\n",
            "episode=147/2500, total_reward=-101.3093, avg_reward=-103.6553, time=49927\n",
            "episode=148/2500, total_reward=-101.0036, avg_reward=-103.5105, time=49983\n",
            "episode=149/2500, total_reward=-102.4302, avg_reward=-103.4331, time=50044\n",
            "episode=150/2500, total_reward=-100.4458, avg_reward=-103.3296, time=50102\n",
            "episode=151/2500, total_reward=-101.2502, avg_reward=-103.2304, time=50166\n",
            "episode=152/2500, total_reward=-101.8399, avg_reward=-103.1555, time=50223\n",
            "episode=153/2500, total_reward=-99.7185, avg_reward=-102.9660, time=50288\n",
            "episode=154/2500, total_reward=-102.0328, avg_reward=-102.8686, time=50344\n",
            "episode=155/2500, total_reward=-102.3923, avg_reward=-102.7875, time=50396\n",
            "episode=156/2500, total_reward=-102.8012, avg_reward=-102.7090, time=50452\n",
            "episode=157/2500, total_reward=-102.1767, avg_reward=-102.5959, time=50516\n",
            "episode=158/2500, total_reward=-102.2847, avg_reward=-102.5167, time=50568\n",
            "episode=159/2500, total_reward=-102.0681, avg_reward=-102.4927, time=50620\n",
            "episode=160/2500, total_reward=-101.5342, avg_reward=-102.3416, time=50670\n",
            "episode=161/2500, total_reward=-102.9283, avg_reward=-102.3196, time=50717\n",
            "episode=162/2500, total_reward=-100.6176, avg_reward=-102.3287, time=50776\n",
            "episode=163/2500, total_reward=-102.0389, avg_reward=-102.2671, time=50828\n",
            "episode=164/2500, total_reward=-103.1540, avg_reward=-102.2245, time=50876\n",
            "episode=165/2500, total_reward=-100.2711, avg_reward=-102.2372, time=50941\n",
            "episode=166/2500, total_reward=-101.2632, avg_reward=-102.2633, time=51006\n",
            "episode=167/2500, total_reward=-103.7086, avg_reward=-102.2179, time=51063\n",
            "episode=168/2500, total_reward=-103.1357, avg_reward=-102.2969, time=51111\n",
            "episode=169/2500, total_reward=-99.2874, avg_reward=-102.1847, time=51171\n",
            "episode=170/2500, total_reward=-101.4520, avg_reward=-102.1255, time=51226\n",
            "episode=171/2500, total_reward=-102.6027, avg_reward=-102.1234, time=51281\n",
            "episode=172/2500, total_reward=-103.7757, avg_reward=-102.0404, time=51325\n",
            "episode=173/2500, total_reward=-103.3473, avg_reward=-102.0781, time=51393\n",
            "episode=174/2500, total_reward=-99.6909, avg_reward=-101.9419, time=51459\n",
            "episode=175/2500, total_reward=-98.7607, avg_reward=-101.6968, time=51533\n",
            "episode=176/2500, total_reward=-100.7389, avg_reward=-101.6865, time=51594\n",
            "episode=177/2500, total_reward=-100.2172, avg_reward=-101.6525, time=51657\n",
            "episode=178/2500, total_reward=-100.1084, avg_reward=-101.6414, time=51723\n",
            "episode=179/2500, total_reward=-99.2205, avg_reward=-101.5906, time=51786\n",
            "episode=180/2500, total_reward=-99.9651, avg_reward=-101.5234, time=51850\n",
            "episode=181/2500, total_reward=-99.3716, avg_reward=-101.3955, time=51917\n",
            "episode=182/2500, total_reward=-99.1259, avg_reward=-101.3587, time=51979\n",
            "episode=183/2500, total_reward=-100.1814, avg_reward=-101.3612, time=52048\n",
            "episode=184/2500, total_reward=-99.8107, avg_reward=-101.3336, time=52110\n",
            "episode=185/2500, total_reward=-100.4080, avg_reward=-101.3238, time=52179\n",
            "episode=186/2500, total_reward=-99.1214, avg_reward=-101.2730, time=52256\n",
            "episode=187/2500, total_reward=-100.1883, avg_reward=-101.2579, time=52319\n",
            "episode=188/2500, total_reward=-99.9828, avg_reward=-101.1915, time=52387\n",
            "episode=189/2500, total_reward=-98.3465, avg_reward=-101.1357, time=52455\n",
            "episode=190/2500, total_reward=-98.3152, avg_reward=-101.0540, time=52521\n",
            "episode=191/2500, total_reward=-99.6753, avg_reward=-100.9988, time=52585\n",
            "episode=192/2500, total_reward=-101.3280, avg_reward=-101.0015, time=52655\n",
            "episode=193/2500, total_reward=-97.5563, avg_reward=-100.9121, time=52723\n",
            "episode=194/2500, total_reward=-97.5046, avg_reward=-100.8435, time=52789\n",
            "episode=195/2500, total_reward=-96.2160, avg_reward=-100.7415, time=52868\n",
            "episode=196/2500, total_reward=-98.0902, avg_reward=-100.6959, time=52934\n",
            "episode=197/2500, total_reward=-99.6910, avg_reward=-100.6635, time=52991\n",
            "episode=198/2500, total_reward=-97.9643, avg_reward=-100.6027, time=53058\n",
            "episode=199/2500, total_reward=-96.4458, avg_reward=-100.4830, time=53126\n",
            "episode=200/2500, total_reward=-96.7453, avg_reward=-100.4090, time=53192\n",
            "episode=201/2500, total_reward=-99.4533, avg_reward=-100.3731, time=53253\n",
            "episode=202/2500, total_reward=-100.3802, avg_reward=-100.3439, time=53310\n",
            "episode=203/2500, total_reward=-98.8589, avg_reward=-100.3267, time=53365\n",
            "episode=204/2500, total_reward=-99.0320, avg_reward=-100.2667, time=53423\n",
            "episode=205/2500, total_reward=-103.2517, avg_reward=-100.2839, time=53469\n",
            "episode=206/2500, total_reward=-103.5664, avg_reward=-100.2992, time=53510\n",
            "episode=207/2500, total_reward=-101.1293, avg_reward=-100.2782, time=53568\n",
            "episode=208/2500, total_reward=-99.5959, avg_reward=-100.2245, time=53631\n",
            "episode=209/2500, total_reward=-99.0251, avg_reward=-100.1636, time=53701\n",
            "episode=210/2500, total_reward=-98.9111, avg_reward=-100.1111, time=53760\n",
            "episode=211/2500, total_reward=-98.0999, avg_reward=-100.0146, time=53822\n",
            "episode=212/2500, total_reward=-98.3809, avg_reward=-99.9698, time=53884\n",
            "episode=213/2500, total_reward=-99.2506, avg_reward=-99.9141, time=53942\n",
            "episode=214/2500, total_reward=-99.5939, avg_reward=-99.8429, time=54005\n",
            "episode=215/2500, total_reward=-98.4607, avg_reward=-99.8067, time=54067\n",
            "episode=216/2500, total_reward=-98.1744, avg_reward=-99.7449, time=54132\n",
            "episode=217/2500, total_reward=-101.0665, avg_reward=-99.6920, time=54181\n",
            "episode=218/2500, total_reward=-96.9587, avg_reward=-99.5685, time=54249\n",
            "episode=219/2500, total_reward=-97.6539, avg_reward=-99.5358, time=54310\n",
            "episode=220/2500, total_reward=-96.0563, avg_reward=-99.4279, time=54384\n",
            "episode=221/2500, total_reward=-96.5507, avg_reward=-99.3069, time=54448\n",
            "episode=222/2500, total_reward=-97.9366, avg_reward=-99.1901, time=54514\n",
            "episode=223/2500, total_reward=-96.5245, avg_reward=-99.0536, time=54578\n",
            "episode=224/2500, total_reward=-97.8276, avg_reward=-99.0164, time=54640\n",
            "episode=225/2500, total_reward=-98.3341, avg_reward=-99.0078, time=54709\n",
            "episode=226/2500, total_reward=-98.2325, avg_reward=-98.9577, time=54773\n",
            "episode=227/2500, total_reward=-97.9105, avg_reward=-98.9116, time=54854\n",
            "episode=228/2500, total_reward=-97.5376, avg_reward=-98.8602, time=54935\n",
            "episode=229/2500, total_reward=-97.3827, avg_reward=-98.8234, time=55015\n",
            "episode=230/2500, total_reward=-95.8705, avg_reward=-98.7415, time=55087\n",
            "episode=231/2500, total_reward=-96.6613, avg_reward=-98.6873, time=55158\n",
            "episode=232/2500, total_reward=-96.0571, avg_reward=-98.6259, time=55238\n",
            "episode=233/2500, total_reward=-96.9428, avg_reward=-98.5612, time=55315\n",
            "episode=234/2500, total_reward=-95.9594, avg_reward=-98.4841, time=55397\n",
            "episode=235/2500, total_reward=-94.6805, avg_reward=-98.3696, time=55488\n",
            "episode=236/2500, total_reward=-100.3129, avg_reward=-98.3934, time=55569\n",
            "episode=237/2500, total_reward=-96.8490, avg_reward=-98.3266, time=55651\n",
            "episode=238/2500, total_reward=-102.3641, avg_reward=-98.3743, time=55716\n",
            "episode=239/2500, total_reward=-97.2300, avg_reward=-98.3519, time=55791\n",
            "episode=240/2500, total_reward=-103.7323, avg_reward=-98.4603, time=55859\n",
            "episode=241/2500, total_reward=-106.1315, avg_reward=-98.5894, time=55904\n",
            "episode=242/2500, total_reward=-104.9940, avg_reward=-98.6627, time=55950\n",
            "episode=243/2500, total_reward=-97.7418, avg_reward=-98.6664, time=56029\n",
            "episode=244/2500, total_reward=-97.5291, avg_reward=-98.6669, time=56100\n",
            "episode=245/2500, total_reward=-96.7967, avg_reward=-98.6785, time=56184\n",
            "episode=246/2500, total_reward=-98.6294, avg_reward=-98.6893, time=56257\n",
            "episode=247/2500, total_reward=-98.6556, avg_reward=-98.6686, time=56333\n",
            "episode=248/2500, total_reward=-95.6968, avg_reward=-98.6233, time=56422\n",
            "episode=249/2500, total_reward=-98.1762, avg_reward=-98.6579, time=56498\n",
            "episode=250/2500, total_reward=-98.0466, avg_reward=-98.6839, time=56585\n",
            "episode=251/2500, total_reward=-99.4861, avg_reward=-98.6845, time=56667\n",
            "episode=252/2500, total_reward=-93.8540, avg_reward=-98.5540, time=56776\n",
            "episode=253/2500, total_reward=-96.4761, avg_reward=-98.5064, time=56871\n",
            "episode=254/2500, total_reward=-96.9526, avg_reward=-98.4648, time=56948\n",
            "episode=255/2500, total_reward=-95.9590, avg_reward=-98.3189, time=57047\n",
            "episode=256/2500, total_reward=-94.8929, avg_reward=-98.1454, time=57139\n",
            "episode=257/2500, total_reward=-96.9059, avg_reward=-98.0610, time=57249\n",
            "episode=258/2500, total_reward=-94.6118, avg_reward=-97.9613, time=57348\n",
            "episode=259/2500, total_reward=-94.5646, avg_reward=-97.8721, time=57451\n",
            "episode=260/2500, total_reward=-94.9376, avg_reward=-97.7926, time=57542\n",
            "episode=261/2500, total_reward=-95.9099, avg_reward=-97.7488, time=57639\n",
            "episode=262/2500, total_reward=-94.8565, avg_reward=-97.6783, time=57723\n",
            "episode=263/2500, total_reward=-94.9861, avg_reward=-97.5930, time=57824\n",
            "episode=264/2500, total_reward=-97.7860, avg_reward=-97.5569, time=57893\n",
            "episode=265/2500, total_reward=-99.4266, avg_reward=-97.5762, time=57986\n",
            "episode=266/2500, total_reward=-95.1656, avg_reward=-97.5160, time=58087\n",
            "episode=267/2500, total_reward=-95.9967, avg_reward=-97.4146, time=58185\n",
            "episode=268/2500, total_reward=-93.7887, avg_reward=-97.3512, time=58293\n",
            "episode=269/2500, total_reward=-94.7171, avg_reward=-97.2925, time=58400\n",
            "episode=270/2500, total_reward=-94.6890, avg_reward=-97.2651, time=58503\n",
            "episode=271/2500, total_reward=-96.0517, avg_reward=-97.2552, time=58596\n",
            "episode=272/2500, total_reward=-96.8020, avg_reward=-97.2325, time=58707\n",
            "episode=273/2500, total_reward=-95.3921, avg_reward=-97.2098, time=58792\n",
            "episode=274/2500, total_reward=-96.8695, avg_reward=-97.1907, time=58878\n",
            "episode=275/2500, total_reward=-95.6265, avg_reward=-97.1365, time=58987\n",
            "episode=276/2500, total_reward=-95.7089, avg_reward=-97.0860, time=59078\n",
            "episode=277/2500, total_reward=-94.9710, avg_reward=-97.0272, time=59180\n",
            "episode=278/2500, total_reward=-93.7391, avg_reward=-96.9513, time=59285\n",
            "episode=279/2500, total_reward=-95.1039, avg_reward=-96.9057, time=59375\n",
            "episode=280/2500, total_reward=-96.3255, avg_reward=-96.9148, time=59453\n",
            "episode=281/2500, total_reward=-96.4464, avg_reward=-96.9105, time=59519\n",
            "episode=282/2500, total_reward=-120.2489, avg_reward=-97.3943, time=59600\n",
            "episode=283/2500, total_reward=-96.6192, avg_reward=-97.3879, time=59720\n",
            "episode=284/2500, total_reward=-96.5038, avg_reward=-97.3988, time=59822\n",
            "episode=285/2500, total_reward=-97.1197, avg_reward=-97.4475, time=59916\n",
            "episode=286/2500, total_reward=-99.3852, avg_reward=-97.4290, time=60002\n",
            "episode=287/2500, total_reward=-99.9631, avg_reward=-97.4913, time=60076\n",
            "episode=288/2500, total_reward=-99.7570, avg_reward=-97.4391, time=60153\n",
            "episode=289/2500, total_reward=-98.1404, avg_reward=-97.4573, time=60225\n",
            "episode=290/2500, total_reward=-94.7164, avg_reward=-97.2770, time=60326\n",
            "episode=291/2500, total_reward=-97.8964, avg_reward=-97.1123, time=60417\n",
            "episode=292/2500, total_reward=-100.0117, avg_reward=-97.0127, time=60483\n",
            "episode=293/2500, total_reward=-100.8531, avg_reward=-97.0749, time=60547\n",
            "episode=294/2500, total_reward=-97.5345, avg_reward=-97.0750, time=60616\n",
            "episode=295/2500, total_reward=-99.5442, avg_reward=-97.1300, time=60699\n",
            "episode=296/2500, total_reward=-102.0752, avg_reward=-97.1989, time=60759\n",
            "episode=297/2500, total_reward=-96.1452, avg_reward=-97.1487, time=60849\n",
            "episode=298/2500, total_reward=-95.0868, avg_reward=-97.1365, time=60954\n",
            "episode=299/2500, total_reward=-99.3579, avg_reward=-97.1601, time=61023\n",
            "episode=300/2500, total_reward=-94.8550, avg_reward=-97.0963, time=61117\n",
            "episode=301/2500, total_reward=-98.7290, avg_reward=-97.0811, time=61189\n",
            "episode=302/2500, total_reward=-96.3092, avg_reward=-97.1302, time=61301\n",
            "episode=303/2500, total_reward=-100.0158, avg_reward=-97.2010, time=61367\n",
            "episode=304/2500, total_reward=-97.9679, avg_reward=-97.2213, time=61442\n",
            "episode=305/2500, total_reward=-99.5542, avg_reward=-97.2932, time=61518\n",
            "episode=306/2500, total_reward=-98.5020, avg_reward=-97.3654, time=61594\n",
            "episode=307/2500, total_reward=-95.4965, avg_reward=-97.3372, time=61683\n",
            "episode=308/2500, total_reward=-100.2107, avg_reward=-97.4492, time=61750\n",
            "episode=309/2500, total_reward=-98.7520, avg_reward=-97.5330, time=61825\n",
            "episode=310/2500, total_reward=-98.6322, avg_reward=-97.6068, time=61898\n",
            "episode=311/2500, total_reward=-99.8513, avg_reward=-97.6857, time=61960\n",
            "episode=312/2500, total_reward=-99.5853, avg_reward=-97.7802, time=62035\n",
            "episode=313/2500, total_reward=-99.2764, avg_reward=-97.8661, time=62102\n",
            "episode=314/2500, total_reward=-98.6362, avg_reward=-97.8831, time=62163\n",
            "episode=315/2500, total_reward=-98.9020, avg_reward=-97.8726, time=62230\n",
            "episode=316/2500, total_reward=-96.3996, avg_reward=-97.8972, time=62302\n",
            "episode=317/2500, total_reward=-96.5094, avg_reward=-97.9075, time=62377\n",
            "episode=318/2500, total_reward=-98.1655, avg_reward=-97.9950, time=62452\n",
            "episode=319/2500, total_reward=-98.4353, avg_reward=-98.0694, time=62519\n",
            "episode=320/2500, total_reward=-95.9219, avg_reward=-98.0941, time=62595\n",
            "episode=321/2500, total_reward=-97.4801, avg_reward=-98.1226, time=62668\n",
            "episode=322/2500, total_reward=-99.1739, avg_reward=-98.1701, time=62732\n",
            "episode=323/2500, total_reward=-97.8456, avg_reward=-98.2191, time=62803\n",
            "episode=324/2500, total_reward=-96.4519, avg_reward=-98.2108, time=62882\n",
            "episode=325/2500, total_reward=-96.6352, avg_reward=-98.2310, time=62964\n",
            "episode=326/2500, total_reward=-98.1299, avg_reward=-98.2794, time=63025\n",
            "episode=327/2500, total_reward=-101.3408, avg_reward=-98.4068, time=63085\n",
            "episode=328/2500, total_reward=-97.7171, avg_reward=-98.4863, time=63153\n",
            "episode=329/2500, total_reward=-96.0103, avg_reward=-98.5045, time=63220\n",
            "episode=330/2500, total_reward=-100.5573, avg_reward=-98.5891, time=63283\n",
            "episode=331/2500, total_reward=-98.8052, avg_reward=-98.6363, time=63347\n",
            "episode=332/2500, total_reward=-100.3608, avg_reward=-98.2385, time=63407\n",
            "episode=333/2500, total_reward=-99.1383, avg_reward=-98.2889, time=63469\n",
            "episode=334/2500, total_reward=-97.2607, avg_reward=-98.3040, time=63542\n",
            "episode=335/2500, total_reward=-96.4146, avg_reward=-98.2899, time=63611\n",
            "episode=336/2500, total_reward=-96.9324, avg_reward=-98.2409, time=63694\n",
            "episode=337/2500, total_reward=-98.0337, avg_reward=-98.2023, time=63769\n",
            "episode=338/2500, total_reward=-100.4272, avg_reward=-98.2157, time=63827\n",
            "episode=339/2500, total_reward=-98.1359, avg_reward=-98.2156, time=63892\n",
            "episode=340/2500, total_reward=-100.3011, avg_reward=-98.3273, time=63952\n",
            "episode=341/2500, total_reward=-97.4615, avg_reward=-98.3186, time=64024\n",
            "episode=342/2500, total_reward=-97.7310, avg_reward=-98.2730, time=64090\n",
            "episode=343/2500, total_reward=-96.6155, avg_reward=-98.1882, time=64171\n",
            "episode=344/2500, total_reward=-95.1935, avg_reward=-98.1414, time=64264\n",
            "episode=345/2500, total_reward=-98.3487, avg_reward=-98.1175, time=64328\n",
            "episode=346/2500, total_reward=-97.6556, avg_reward=-98.0291, time=64406\n",
            "episode=347/2500, total_reward=-97.7380, avg_reward=-98.0610, time=64472\n",
            "episode=348/2500, total_reward=-104.2865, avg_reward=-98.2449, time=64525\n",
            "episode=349/2500, total_reward=-104.4697, avg_reward=-98.3472, time=64575\n",
            "episode=350/2500, total_reward=-97.5493, avg_reward=-98.4011, time=64644\n",
            "episode=351/2500, total_reward=-99.7897, avg_reward=-98.4223, time=64703\n",
            "episode=352/2500, total_reward=-96.0034, avg_reward=-98.4162, time=64777\n",
            "episode=353/2500, total_reward=-94.7393, avg_reward=-98.3106, time=64864\n",
            "episode=354/2500, total_reward=-98.8239, avg_reward=-98.3278, time=64937\n",
            "episode=355/2500, total_reward=-101.7059, avg_reward=-98.3708, time=64987\n",
            "episode=356/2500, total_reward=-102.5512, avg_reward=-98.4518, time=65045\n",
            "episode=357/2500, total_reward=-98.2671, avg_reward=-98.5072, time=65109\n",
            "episode=358/2500, total_reward=-98.0891, avg_reward=-98.4648, time=65181\n",
            "episode=359/2500, total_reward=-97.8759, avg_reward=-98.4472, time=65250\n",
            "episode=360/2500, total_reward=-95.0617, avg_reward=-98.3758, time=65333\n",
            "episode=361/2500, total_reward=-100.0034, avg_reward=-98.3789, time=65401\n",
            "episode=362/2500, total_reward=-98.3182, avg_reward=-98.3535, time=65487\n",
            "episode=363/2500, total_reward=-99.6886, avg_reward=-98.3618, time=65558\n",
            "episode=364/2500, total_reward=-95.6855, avg_reward=-98.3028, time=65648\n",
            "episode=365/2500, total_reward=-96.8449, avg_reward=-98.2616, time=65728\n",
            "episode=366/2500, total_reward=-97.2921, avg_reward=-98.2795, time=65804\n",
            "episode=367/2500, total_reward=-101.8948, avg_reward=-98.3872, time=65878\n",
            "episode=368/2500, total_reward=-105.5387, avg_reward=-98.5346, time=65935\n",
            "episode=369/2500, total_reward=-100.4068, avg_reward=-98.5741, time=65993\n",
            "episode=370/2500, total_reward=-95.5284, avg_reward=-98.5662, time=66076\n",
            "episode=371/2500, total_reward=-97.6522, avg_reward=-98.5696, time=66141\n",
            "episode=372/2500, total_reward=-97.9669, avg_reward=-98.5455, time=66210\n",
            "episode=373/2500, total_reward=-97.4953, avg_reward=-98.5385, time=66289\n",
            "episode=374/2500, total_reward=-104.6462, avg_reward=-98.7024, time=66342\n",
            "episode=375/2500, total_reward=-99.0654, avg_reward=-98.7510, time=66410\n",
            "episode=376/2500, total_reward=-99.8063, avg_reward=-98.7845, time=66475\n",
            "episode=377/2500, total_reward=-100.0206, avg_reward=-98.7581, time=66537\n",
            "episode=378/2500, total_reward=-98.2713, avg_reward=-98.7692, time=66604\n",
            "episode=379/2500, total_reward=-96.7797, avg_reward=-98.7846, time=66688\n",
            "episode=380/2500, total_reward=-102.8654, avg_reward=-98.8307, time=66748\n",
            "episode=381/2500, total_reward=-99.7950, avg_reward=-98.8505, time=66815\n",
            "episode=382/2500, total_reward=-99.1536, avg_reward=-98.8264, time=66889\n",
            "episode=383/2500, total_reward=-96.5528, avg_reward=-98.7747, time=66953\n",
            "episode=384/2500, total_reward=-95.6226, avg_reward=-98.7419, time=67038\n",
            "episode=385/2500, total_reward=-100.0929, avg_reward=-98.8155, time=67096\n",
            "episode=386/2500, total_reward=-102.4723, avg_reward=-98.9263, time=67156\n",
            "episode=387/2500, total_reward=-98.8909, avg_reward=-98.9434, time=67222\n",
            "episode=388/2500, total_reward=-97.5541, avg_reward=-98.8860, time=67297\n",
            "episode=389/2500, total_reward=-101.2898, avg_reward=-98.9491, time=67360\n",
            "episode=390/2500, total_reward=-95.9821, avg_reward=-98.8627, time=67431\n",
            "episode=391/2500, total_reward=-98.0226, avg_reward=-98.8739, time=67496\n",
            "episode=392/2500, total_reward=-104.9239, avg_reward=-99.0177, time=67556\n",
            "episode=393/2500, total_reward=-102.2889, avg_reward=-99.1312, time=67614\n",
            "episode=394/2500, total_reward=-100.3288, avg_reward=-99.2339, time=67671\n",
            "episode=395/2500, total_reward=-99.0384, avg_reward=-99.2477, time=67742\n",
            "episode=396/2500, total_reward=-123.1683, avg_reward=-99.7580, time=68431\n",
            "episode=397/2500, total_reward=-98.7229, avg_reward=-99.7777, time=68491\n",
            "episode=398/2500, total_reward=-98.2817, avg_reward=-99.6576, time=68616\n",
            "episode=399/2500, total_reward=-98.8197, avg_reward=-99.5446, time=68677\n",
            "episode=400/2500, total_reward=-96.8662, avg_reward=-99.5309, time=68750\n",
            "episode=401/2500, total_reward=-102.0582, avg_reward=-99.5763, time=68936\n",
            "episode=402/2500, total_reward=-98.0379, avg_reward=-99.6170, time=69008\n",
            "episode=403/2500, total_reward=-100.9501, avg_reward=-99.7412, time=69172\n",
            "episode=404/2500, total_reward=-102.5857, avg_reward=-99.8164, time=69240\n",
            "episode=405/2500, total_reward=-103.1490, avg_reward=-99.8453, time=69311\n",
            "episode=406/2500, total_reward=-98.1383, avg_reward=-99.7570, time=69384\n",
            "episode=407/2500, total_reward=-106.6740, avg_reward=-99.9252, time=69460\n",
            "episode=408/2500, total_reward=-104.6714, avg_reward=-100.0568, time=69572\n",
            "episode=409/2500, total_reward=-97.6009, avg_reward=-100.0513, time=69643\n",
            "episode=410/2500, total_reward=-138.9832, avg_reward=-100.9297, time=70714\n",
            "episode=411/2500, total_reward=-138.6667, avg_reward=-101.7030, time=71532\n",
            "episode=412/2500, total_reward=-112.2373, avg_reward=-101.9814, time=71910\n",
            "episode=413/2500, total_reward=-109.3274, avg_reward=-102.1742, time=72020\n",
            "episode=414/2500, total_reward=-112.3336, avg_reward=-102.5071, time=72161\n",
            "episode=415/2500, total_reward=-99.3395, avg_reward=-102.5570, time=72235\n",
            "episode=416/2500, total_reward=-108.1484, avg_reward=-102.7741, time=72483\n",
            "episode=417/2500, total_reward=-105.7964, avg_reward=-102.8522, time=72612\n",
            "episode=418/2500, total_reward=-94.6150, avg_reward=-102.6337, time=72729\n",
            "episode=419/2500, total_reward=-112.3510, avg_reward=-102.8726, time=73021\n",
            "episode=420/2500, total_reward=-108.8720, avg_reward=-103.1395, time=73249\n",
            "episode=421/2500, total_reward=-95.0617, avg_reward=-103.0876, time=73389\n",
            "episode=422/2500, total_reward=-75.7608, avg_reward=-102.6435, time=74989\n",
            "episode=423/2500, total_reward=-146.0236, avg_reward=-103.6141, time=75842\n",
            "episode=424/2500, total_reward=-88.3148, avg_reward=-103.2875, time=77442\n",
            "episode=425/2500, total_reward=-93.7438, avg_reward=-103.1810, time=77542\n",
            "episode=426/2500, total_reward=-112.9425, avg_reward=-103.4438, time=77595\n",
            "episode=427/2500, total_reward=-130.8355, avg_reward=-104.0601, time=77742\n",
            "episode=428/2500, total_reward=-114.4619, avg_reward=-104.3839, time=77797\n",
            "episode=429/2500, total_reward=-113.8715, avg_reward=-104.7257, time=77862\n",
            "episode=430/2500, total_reward=-113.2373, avg_reward=-104.9331, time=77931\n",
            "episode=431/2500, total_reward=-116.2020, avg_reward=-105.2613, time=77999\n",
            "episode=432/2500, total_reward=-109.2844, avg_reward=-105.4639, time=78047\n",
            "episode=433/2500, total_reward=-121.4972, avg_reward=-105.9628, time=78155\n",
            "episode=434/2500, total_reward=-108.7632, avg_reward=-106.2256, time=78203\n",
            "episode=435/2500, total_reward=-109.4484, avg_reward=-106.4127, time=78250\n",
            "episode=436/2500, total_reward=-102.5658, avg_reward=-106.4146, time=78350\n",
            "episode=437/2500, total_reward=-110.0308, avg_reward=-106.6374, time=78400\n",
            "episode=438/2500, total_reward=-116.5609, avg_reward=-107.0175, time=78464\n",
            "episode=439/2500, total_reward=-122.7510, avg_reward=-107.4467, time=78594\n",
            "episode=440/2500, total_reward=-112.1248, avg_reward=-107.7696, time=78687\n",
            "episode=441/2500, total_reward=-107.7075, avg_reward=-107.9633, time=78734\n",
            "episode=442/2500, total_reward=-118.7003, avg_reward=-108.2388, time=78818\n",
            "episode=443/2500, total_reward=-122.1092, avg_reward=-108.6352, time=78911\n",
            "episode=444/2500, total_reward=-108.6887, avg_reward=-108.8024, time=78956\n",
            "episode=445/2500, total_reward=-108.1273, avg_reward=-108.9842, time=79000\n",
            "episode=446/2500, total_reward=-108.3052, avg_reward=-108.6869, time=79046\n",
            "episode=447/2500, total_reward=-107.0501, avg_reward=-108.8535, time=79092\n",
            "episode=448/2500, total_reward=-122.3774, avg_reward=-109.3354, time=79209\n",
            "episode=449/2500, total_reward=-117.8713, avg_reward=-109.7164, time=79316\n",
            "episode=450/2500, total_reward=-95.3068, avg_reward=-109.6852, time=79474\n",
            "episode=451/2500, total_reward=-105.9855, avg_reward=-109.7638, time=79551\n",
            "episode=452/2500, total_reward=-93.1569, avg_reward=-109.6662, time=79727\n",
            "episode=453/2500, total_reward=-106.9700, avg_reward=-109.7866, time=79816\n",
            "episode=454/2500, total_reward=-103.1979, avg_reward=-109.7988, time=79948\n",
            "episode=455/2500, total_reward=-146.7961, avg_reward=-110.6717, time=80732\n",
            "episode=456/2500, total_reward=-101.4794, avg_reward=-110.7386, time=80834\n",
            "episode=457/2500, total_reward=-116.5023, avg_reward=-110.9351, time=80975\n",
            "episode=458/2500, total_reward=-107.4435, avg_reward=-110.9906, time=81106\n",
            "episode=459/2500, total_reward=-105.8728, avg_reward=-111.1560, time=81193\n",
            "episode=460/2500, total_reward=-102.9898, avg_reward=-110.4361, time=81265\n",
            "episode=461/2500, total_reward=-149.3591, avg_reward=-110.6500, time=82138\n",
            "episode=462/2500, total_reward=-101.3615, avg_reward=-110.4325, time=82216\n",
            "episode=463/2500, total_reward=-98.8962, avg_reward=-110.2239, time=82314\n",
            "episode=464/2500, total_reward=-97.7268, avg_reward=-109.9317, time=82397\n",
            "episode=465/2500, total_reward=-96.5415, avg_reward=-109.8758, time=82583\n",
            "episode=466/2500, total_reward=-102.2933, avg_reward=-109.7587, time=82670\n",
            "episode=467/2500, total_reward=-101.8482, avg_reward=-109.6797, time=82766\n",
            "episode=468/2500, total_reward=-101.6565, avg_reward=-109.8205, time=82840\n",
            "episode=469/2500, total_reward=-100.6945, avg_reward=-109.5874, time=82916\n",
            "episode=470/2500, total_reward=-96.2077, avg_reward=-109.3341, time=83011\n",
            "episode=471/2500, total_reward=-98.0212, avg_reward=-109.3933, time=83100\n",
            "episode=472/2500, total_reward=-102.4771, avg_reward=-109.9276, time=83179\n",
            "episode=473/2500, total_reward=-97.8757, avg_reward=-108.9647, time=83297\n",
            "episode=474/2500, total_reward=-99.0406, avg_reward=-109.1792, time=83401\n",
            "episode=475/2500, total_reward=-100.3852, avg_reward=-109.3120, time=83528\n",
            "episode=476/2500, total_reward=-100.7515, avg_reward=-109.0682, time=83616\n",
            "episode=477/2500, total_reward=-102.3771, avg_reward=-108.4990, time=83683\n",
            "episode=478/2500, total_reward=-93.6328, avg_reward=-108.0824, time=83820\n",
            "episode=479/2500, total_reward=-97.2194, avg_reward=-107.7494, time=83899\n",
            "episode=480/2500, total_reward=-102.3512, avg_reward=-107.5317, time=84057\n",
            "episode=481/2500, total_reward=-99.9186, avg_reward=-107.2060, time=84167\n",
            "episode=482/2500, total_reward=-99.7444, avg_reward=-107.0152, time=84251\n",
            "episode=483/2500, total_reward=-98.1161, avg_reward=-106.5476, time=84370\n",
            "episode=484/2500, total_reward=-103.2447, avg_reward=-106.4372, time=84432\n",
            "episode=485/2500, total_reward=-106.4163, avg_reward=-106.3766, time=84607\n",
            "episode=486/2500, total_reward=-99.6759, avg_reward=-106.3188, time=84764\n",
            "episode=487/2500, total_reward=-102.4582, avg_reward=-106.1673, time=84842\n",
            "episode=488/2500, total_reward=-102.4659, avg_reward=-105.8854, time=84925\n",
            "episode=489/2500, total_reward=-94.9101, avg_reward=-105.3286, time=85073\n",
            "episode=490/2500, total_reward=-100.3434, avg_reward=-105.0930, time=85153\n",
            "episode=491/2500, total_reward=-97.7355, avg_reward=-104.8935, time=85235\n",
            "episode=492/2500, total_reward=-102.3970, avg_reward=-104.5675, time=85311\n",
            "episode=493/2500, total_reward=-101.4708, avg_reward=-104.1547, time=85442\n",
            "episode=494/2500, total_reward=-99.6397, avg_reward=-103.9737, time=85530\n",
            "episode=495/2500, total_reward=-103.6352, avg_reward=-103.8839, time=85603\n",
            "episode=496/2500, total_reward=-100.8535, avg_reward=-103.7348, time=85705\n",
            "episode=497/2500, total_reward=-97.9526, avg_reward=-103.5529, time=85862\n",
            "episode=498/2500, total_reward=-101.8041, avg_reward=-103.1414, time=85935\n",
            "episode=499/2500, total_reward=-98.6320, avg_reward=-102.7566, time=86015\n",
            "episode=500/2500, total_reward=-98.7220, avg_reward=-102.8249, time=86111\n",
            "episode=501/2500, total_reward=-100.5037, avg_reward=-102.7153, time=86194\n",
            "episode=502/2500, total_reward=-99.7241, avg_reward=-102.8467, time=86277\n",
            "episode=503/2500, total_reward=-100.1286, avg_reward=-102.7098, time=86412\n",
            "episode=504/2500, total_reward=-98.5739, avg_reward=-102.6173, time=86575\n",
            "episode=505/2500, total_reward=-99.8637, avg_reward=-101.6787, time=86665\n",
            "episode=506/2500, total_reward=-98.0955, avg_reward=-101.6110, time=86769\n",
            "episode=507/2500, total_reward=-108.4537, avg_reward=-101.4500, time=86927\n",
            "episode=508/2500, total_reward=-99.9372, avg_reward=-101.2999, time=87003\n",
            "episode=509/2500, total_reward=-105.6373, avg_reward=-101.2952, time=87116\n",
            "episode=510/2500, total_reward=-100.9033, avg_reward=-101.2535, time=87295\n",
            "episode=511/2500, total_reward=-101.8338, avg_reward=-100.3030, time=87366\n",
            "episode=512/2500, total_reward=-102.8852, avg_reward=-100.3334, time=87435\n",
            "episode=513/2500, total_reward=-100.6474, avg_reward=-100.3685, time=87512\n",
            "episode=514/2500, total_reward=-105.4745, avg_reward=-100.5234, time=87679\n",
            "episode=515/2500, total_reward=-105.3400, avg_reward=-100.6994, time=87778\n",
            "episode=516/2500, total_reward=-97.5835, avg_reward=-100.6052, time=87914\n",
            "episode=517/2500, total_reward=-100.4610, avg_reward=-100.5775, time=87990\n",
            "episode=518/2500, total_reward=-98.2770, avg_reward=-100.5099, time=88075\n",
            "episode=519/2500, total_reward=-99.3728, avg_reward=-100.4834, time=88144\n",
            "episode=520/2500, total_reward=-99.1751, avg_reward=-100.5428, time=88278\n",
            "episode=521/2500, total_reward=-98.2046, avg_reward=-100.5464, time=88359\n",
            "episode=522/2500, total_reward=-104.5237, avg_reward=-100.5874, time=88476\n",
            "episode=523/2500, total_reward=-102.6798, avg_reward=-100.6835, time=88547\n",
            "episode=524/2500, total_reward=-108.3059, avg_reward=-100.8688, time=88827\n",
            "episode=525/2500, total_reward=-101.7281, avg_reward=-100.8956, time=88933\n",
            "episode=526/2500, total_reward=-99.3779, avg_reward=-100.8682, time=89014\n",
            "episode=527/2500, total_reward=-97.6206, avg_reward=-100.7730, time=89110\n",
            "episode=528/2500, total_reward=-96.9078, avg_reward=-100.8385, time=89200\n",
            "episode=529/2500, total_reward=-105.0839, avg_reward=-100.9958, time=89459\n",
            "episode=530/2500, total_reward=-108.7823, avg_reward=-101.1244, time=89611\n",
            "episode=531/2500, total_reward=-97.2075, avg_reward=-101.0702, time=89701\n",
            "episode=532/2500, total_reward=-142.9392, avg_reward=-101.9341, time=90646\n",
            "episode=533/2500, total_reward=-102.9851, avg_reward=-102.0315, time=90761\n",
            "episode=534/2500, total_reward=-95.8891, avg_reward=-101.8844, time=90873\n",
            "episode=535/2500, total_reward=-90.0825, avg_reward=-101.5577, time=91048\n",
            "episode=536/2500, total_reward=-90.3015, avg_reward=-101.3702, time=91198\n",
            "episode=537/2500, total_reward=-102.7703, avg_reward=-101.3765, time=91509\n",
            "episode=538/2500, total_reward=-101.4916, avg_reward=-101.3570, time=92391\n",
            "episode=539/2500, total_reward=-117.9063, avg_reward=-101.8169, time=93111\n",
            "episode=540/2500, total_reward=-95.9735, avg_reward=-101.7295, time=93222\n",
            "episode=541/2500, total_reward=-123.0501, avg_reward=-102.2358, time=93926\n",
            "episode=542/2500, total_reward=-109.9839, avg_reward=-102.3875, time=94095\n",
            "episode=543/2500, total_reward=-93.8924, avg_reward=-102.2360, time=94285\n",
            "episode=544/2500, total_reward=-97.1351, avg_reward=-102.1859, time=94399\n",
            "episode=545/2500, total_reward=-94.4394, avg_reward=-102.0020, time=94510\n",
            "episode=546/2500, total_reward=-97.1490, avg_reward=-101.9279, time=95344\n",
            "episode=547/2500, total_reward=-106.6763, avg_reward=-102.1023, time=95634\n",
            "episode=548/2500, total_reward=-110.2046, avg_reward=-102.2703, time=96024\n",
            "episode=549/2500, total_reward=-126.5667, avg_reward=-102.8290, time=97266\n",
            "episode=550/2500, total_reward=-122.1875, avg_reward=-103.2983, time=98376\n",
            "episode=551/2500, total_reward=-103.6465, avg_reward=-103.3612, time=98630\n",
            "episode=552/2500, total_reward=-93.2171, avg_reward=-103.2311, time=98864\n",
            "episode=553/2500, total_reward=-95.4779, avg_reward=-103.1380, time=98949\n",
            "episode=554/2500, total_reward=-92.9721, avg_reward=-103.0260, time=99078\n",
            "episode=555/2500, total_reward=-95.4831, avg_reward=-102.9384, time=99201\n",
            "episode=556/2500, total_reward=-94.3351, avg_reward=-102.8632, time=99294\n",
            "episode=557/2500, total_reward=-92.0314, avg_reward=-102.5347, time=99458\n",
            "episode=558/2500, total_reward=-92.5566, avg_reward=-102.3871, time=99673\n",
            "episode=559/2500, total_reward=-94.8909, avg_reward=-102.1722, time=99838\n",
            "episode=560/2500, total_reward=-94.3584, avg_reward=-102.0413, time=99963\n",
            "episode=561/2500, total_reward=-101.7894, avg_reward=-102.0404, time=100050\n",
            "episode=562/2500, total_reward=-95.7296, avg_reward=-101.8973, time=100131\n",
            "episode=563/2500, total_reward=-98.8114, avg_reward=-101.8606, time=100207\n",
            "episode=564/2500, total_reward=-93.5187, avg_reward=-101.6215, time=100336\n",
            "episode=565/2500, total_reward=-95.5954, avg_reward=-101.4266, time=100411\n",
            "episode=566/2500, total_reward=-94.0455, avg_reward=-101.3558, time=100560\n",
            "episode=567/2500, total_reward=-98.8228, avg_reward=-101.3231, time=100647\n",
            "episode=568/2500, total_reward=-93.9983, avg_reward=-101.2375, time=100744\n",
            "episode=569/2500, total_reward=-91.7589, avg_reward=-101.0852, time=100913\n",
            "episode=570/2500, total_reward=-94.2290, avg_reward=-100.9863, time=101012\n",
            "episode=571/2500, total_reward=-86.7583, avg_reward=-100.7574, time=101259\n",
            "episode=572/2500, total_reward=-99.5740, avg_reward=-100.6584, time=101348\n",
            "episode=573/2500, total_reward=-95.3699, avg_reward=-100.5122, time=101444\n",
            "episode=574/2500, total_reward=-94.4650, avg_reward=-100.2353, time=101548\n",
            "episode=575/2500, total_reward=-94.3563, avg_reward=-100.0879, time=101665\n",
            "episode=576/2500, total_reward=-94.6333, avg_reward=-99.9930, time=101774\n",
            "episode=577/2500, total_reward=-88.2262, avg_reward=-99.8051, time=102412\n",
            "episode=578/2500, total_reward=-96.7246, avg_reward=-99.8015, time=102550\n",
            "episode=579/2500, total_reward=-94.4899, avg_reward=-99.5896, time=102654\n",
            "episode=580/2500, total_reward=-95.1918, avg_reward=-99.3178, time=102872\n",
            "episode=581/2500, total_reward=-98.6836, avg_reward=-99.3473, time=102950\n",
            "episode=582/2500, total_reward=-96.0195, avg_reward=-98.4089, time=103052\n",
            "episode=583/2500, total_reward=-95.9108, avg_reward=-98.2674, time=103276\n",
            "episode=584/2500, total_reward=-95.8019, avg_reward=-98.2657, time=103386\n",
            "episode=585/2500, total_reward=-94.8456, avg_reward=-98.3609, time=103479\n",
            "episode=586/2500, total_reward=-93.1294, avg_reward=-98.4175, time=103591\n",
            "episode=587/2500, total_reward=-95.0567, avg_reward=-98.2632, time=103683\n",
            "episode=588/2500, total_reward=-94.9561, avg_reward=-98.1325, time=103780\n",
            "episode=589/2500, total_reward=-98.3884, avg_reward=-97.7422, time=103857\n",
            "episode=590/2500, total_reward=-99.4105, avg_reward=-97.8109, time=104055\n",
            "episode=591/2500, total_reward=-93.4098, avg_reward=-97.2181, time=104180\n",
            "episode=592/2500, total_reward=-94.7422, avg_reward=-96.9133, time=104270\n",
            "episode=593/2500, total_reward=-95.6068, avg_reward=-96.9475, time=104398\n",
            "episode=594/2500, total_reward=-94.1418, avg_reward=-96.8877, time=104480\n",
            "episode=595/2500, total_reward=-92.8238, avg_reward=-96.8554, time=104643\n",
            "episode=596/2500, total_reward=-105.1833, avg_reward=-97.0161, time=106243\n",
            "episode=597/2500, total_reward=-98.0754, avg_reward=-96.8440, time=106357\n",
            "episode=598/2500, total_reward=-101.3618, avg_reward=-96.6672, time=106529\n",
            "episode=599/2500, total_reward=-91.6897, avg_reward=-95.9696, time=106661\n",
            "episode=600/2500, total_reward=-93.0720, avg_reward=-95.3873, time=106780\n",
            "episode=601/2500, total_reward=-95.2126, avg_reward=-95.2187, time=106877\n",
            "episode=602/2500, total_reward=-108.3469, avg_reward=-95.5212, time=107204\n",
            "episode=603/2500, total_reward=-95.8924, avg_reward=-95.5295, time=107330\n",
            "episode=604/2500, total_reward=-93.8937, avg_reward=-95.5480, time=107428\n",
            "episode=605/2500, total_reward=-94.5721, avg_reward=-95.5297, time=107537\n",
            "episode=606/2500, total_reward=-94.9015, avg_reward=-95.5411, time=107675\n",
            "episode=607/2500, total_reward=-98.2175, avg_reward=-95.6648, time=107772\n",
            "episode=608/2500, total_reward=-97.1634, avg_reward=-95.7569, time=107928\n",
            "episode=609/2500, total_reward=-99.3136, avg_reward=-95.8454, time=108046\n",
            "episode=610/2500, total_reward=-100.6368, avg_reward=-95.9710, time=108143\n",
            "episode=611/2500, total_reward=-100.8698, avg_reward=-95.9526, time=108261\n",
            "episode=612/2500, total_reward=-111.2710, avg_reward=-96.2634, time=108779\n",
            "episode=613/2500, total_reward=-100.9484, avg_reward=-96.3061, time=108996\n",
            "episode=614/2500, total_reward=-94.3599, avg_reward=-96.3230, time=109099\n",
            "episode=615/2500, total_reward=-84.8536, avg_reward=-96.1081, time=110699\n",
            "episode=616/2500, total_reward=-98.5482, avg_reward=-96.1982, time=111011\n",
            "episode=617/2500, total_reward=-93.1276, avg_reward=-96.0843, time=111166\n",
            "episode=618/2500, total_reward=-90.6360, avg_reward=-96.0170, time=111719\n",
            "episode=619/2500, total_reward=-94.9437, avg_reward=-96.0807, time=111821\n",
            "episode=620/2500, total_reward=-97.9576, avg_reward=-96.1553, time=112370\n",
            "episode=621/2500, total_reward=-45.5285, avg_reward=-95.3307, time=113970\n",
            "episode=622/2500, total_reward=-91.9265, avg_reward=-95.1777, time=114588\n",
            "episode=623/2500, total_reward=-93.9041, avg_reward=-95.1484, time=114685\n",
            "episode=624/2500, total_reward=-103.2618, avg_reward=-95.3244, time=115288\n",
            "episode=625/2500, total_reward=-91.9618, avg_reward=-95.2765, time=115402\n",
            "episode=626/2500, total_reward=-106.0644, avg_reward=-95.5051, time=116631\n",
            "episode=627/2500, total_reward=-91.8296, avg_reward=-95.5772, time=116819\n",
            "episode=628/2500, total_reward=-93.7430, avg_reward=-95.5175, time=116926\n",
            "episode=629/2500, total_reward=-96.6818, avg_reward=-95.5614, time=117020\n",
            "episode=630/2500, total_reward=-95.4541, avg_reward=-95.5666, time=117136\n",
            "episode=631/2500, total_reward=-102.2024, avg_reward=-95.6370, time=117321\n",
            "episode=632/2500, total_reward=-90.1470, avg_reward=-95.5195, time=117586\n",
            "episode=633/2500, total_reward=-91.5500, avg_reward=-95.4323, time=117799\n",
            "episode=634/2500, total_reward=-93.8261, avg_reward=-95.3928, time=117978\n",
            "episode=635/2500, total_reward=-96.8378, avg_reward=-95.4327, time=118064\n",
            "episode=636/2500, total_reward=-94.5662, avg_reward=-95.4614, time=118272\n",
            "episode=637/2500, total_reward=-99.6611, avg_reward=-95.5535, time=118420\n",
            "episode=638/2500, total_reward=-94.8052, avg_reward=-95.5505, time=118534\n",
            "episode=639/2500, total_reward=-97.2441, avg_reward=-95.5276, time=118666\n",
            "episode=640/2500, total_reward=-96.5870, avg_reward=-95.4711, time=118765\n",
            "episode=641/2500, total_reward=-99.2750, avg_reward=-95.5884, time=118836\n",
            "episode=642/2500, total_reward=-95.5335, avg_reward=-95.6042, time=118932\n",
            "episode=643/2500, total_reward=-94.0924, avg_reward=-95.5739, time=119049\n",
            "episode=644/2500, total_reward=-95.5317, avg_reward=-95.6017, time=119160\n",
            "episode=645/2500, total_reward=-91.5653, avg_reward=-95.5766, time=119292\n",
            "episode=646/2500, total_reward=-93.4737, avg_reward=-95.3424, time=119588\n",
            "episode=647/2500, total_reward=-96.7654, avg_reward=-95.3162, time=119753\n",
            "episode=648/2500, total_reward=-97.7992, avg_reward=-95.2449, time=119848\n",
            "episode=649/2500, total_reward=-95.2210, avg_reward=-95.3156, time=120002\n",
            "episode=650/2500, total_reward=-95.5347, avg_reward=-95.3648, time=120153\n",
            "episode=651/2500, total_reward=-90.5023, avg_reward=-95.2706, time=120308\n",
            "episode=652/2500, total_reward=-87.4518, avg_reward=-94.8527, time=120547\n",
            "episode=653/2500, total_reward=-93.8049, avg_reward=-94.8110, time=120646\n",
            "episode=654/2500, total_reward=-94.3489, avg_reward=-94.8201, time=120779\n",
            "episode=655/2500, total_reward=-89.7960, avg_reward=-94.7245, time=120982\n",
            "episode=656/2500, total_reward=-71.9741, avg_reward=-94.2660, time=121605\n",
            "episode=657/2500, total_reward=-97.3916, avg_reward=-94.2495, time=121705\n",
            "episode=658/2500, total_reward=-89.0379, avg_reward=-94.0870, time=121915\n",
            "episode=659/2500, total_reward=-93.6360, avg_reward=-93.9734, time=122038\n",
            "episode=660/2500, total_reward=-85.1807, avg_reward=-93.6643, time=122323\n",
            "episode=661/2500, total_reward=-92.4854, avg_reward=-93.4966, time=122457\n",
            "episode=662/2500, total_reward=-91.4418, avg_reward=-93.1000, time=122622\n",
            "episode=663/2500, total_reward=-94.8287, avg_reward=-92.9776, time=122719\n",
            "episode=664/2500, total_reward=-94.8126, avg_reward=-92.9867, time=122803\n",
            "episode=665/2500, total_reward=-94.9089, avg_reward=-93.1878, time=122906\n",
            "episode=666/2500, total_reward=-93.4760, avg_reward=-93.0863, time=123012\n",
            "episode=667/2500, total_reward=-80.7185, avg_reward=-92.8382, time=123315\n",
            "episode=668/2500, total_reward=-86.4085, avg_reward=-92.7536, time=123603\n",
            "episode=669/2500, total_reward=-93.9349, avg_reward=-92.7334, time=123735\n",
            "episode=670/2500, total_reward=-96.9718, avg_reward=-92.7137, time=123849\n",
            "episode=671/2500, total_reward=-93.2944, avg_reward=-93.6690, time=123955\n",
            "episode=672/2500, total_reward=-96.2639, avg_reward=-93.7558, time=124066\n",
            "episode=673/2500, total_reward=-90.2934, avg_reward=-93.6836, time=124276\n",
            "episode=674/2500, total_reward=-98.4033, avg_reward=-93.5864, time=124366\n",
            "episode=675/2500, total_reward=-86.8732, avg_reward=-93.4846, time=124671\n",
            "episode=676/2500, total_reward=-94.0576, avg_reward=-93.2445, time=124836\n",
            "episode=677/2500, total_reward=-93.1445, avg_reward=-93.2708, time=125053\n",
            "episode=678/2500, total_reward=-94.5374, avg_reward=-93.2867, time=125211\n",
            "episode=679/2500, total_reward=-85.7081, avg_reward=-93.0672, time=125449\n",
            "episode=680/2500, total_reward=-94.5131, avg_reward=-93.0484, time=125563\n",
            "episode=681/2500, total_reward=-93.5496, avg_reward=-92.8753, time=125678\n",
            "episode=682/2500, total_reward=-90.6420, avg_reward=-92.8852, time=125878\n",
            "episode=683/2500, total_reward=-92.5658, avg_reward=-92.9055, time=125992\n",
            "episode=684/2500, total_reward=-88.6773, avg_reward=-92.8026, time=126221\n",
            "episode=685/2500, total_reward=-88.4973, avg_reward=-92.6357, time=126393\n",
            "episode=686/2500, total_reward=-87.9055, avg_reward=-92.5025, time=126610\n",
            "episode=687/2500, total_reward=-92.6550, avg_reward=-92.3624, time=126749\n",
            "episode=688/2500, total_reward=-104.7833, avg_reward=-92.5620, time=126816\n",
            "episode=689/2500, total_reward=-98.4115, avg_reward=-92.5853, time=126915\n",
            "episode=690/2500, total_reward=-92.9561, avg_reward=-92.5127, time=127061\n",
            "episode=691/2500, total_reward=-95.5603, avg_reward=-92.4384, time=127193\n",
            "episode=692/2500, total_reward=-93.2815, avg_reward=-92.3934, time=127330\n",
            "episode=693/2500, total_reward=-95.9536, avg_reward=-92.4306, time=127417\n",
            "episode=694/2500, total_reward=-94.3613, avg_reward=-92.4072, time=127561\n",
            "episode=695/2500, total_reward=-93.5012, avg_reward=-92.4459, time=127709\n",
            "episode=696/2500, total_reward=-94.6709, avg_reward=-92.4698, time=127809\n",
            "episode=697/2500, total_reward=-97.4989, avg_reward=-92.4845, time=127946\n",
            "episode=698/2500, total_reward=-92.5955, avg_reward=-92.3804, time=128134\n",
            "episode=699/2500, total_reward=-96.8806, avg_reward=-92.4136, time=128250\n",
            "episode=700/2500, total_reward=-93.8431, avg_reward=-92.3798, time=128414\n",
            "episode=701/2500, total_reward=-88.3785, avg_reward=-92.3373, time=128604\n",
            "episode=702/2500, total_reward=-91.8040, avg_reward=-92.4244, time=128860\n",
            "episode=703/2500, total_reward=-97.7549, avg_reward=-92.5034, time=129047\n",
            "episode=704/2500, total_reward=-93.6241, avg_reward=-92.4889, time=129175\n",
            "episode=705/2500, total_reward=-94.7509, avg_reward=-92.5880, time=129295\n",
            "episode=706/2500, total_reward=-93.2277, avg_reward=-93.0130, time=129423\n",
            "episode=707/2500, total_reward=-96.6467, avg_reward=-92.9981, time=129595\n",
            "episode=708/2500, total_reward=-94.4744, avg_reward=-93.1069, time=129700\n",
            "episode=709/2500, total_reward=-94.0934, avg_reward=-93.1160, time=129870\n",
            "episode=710/2500, total_reward=-92.4152, avg_reward=-93.2607, time=129994\n",
            "episode=711/2500, total_reward=-93.8765, avg_reward=-93.2885, time=130110\n",
            "episode=712/2500, total_reward=-91.6101, avg_reward=-93.2919, time=130239\n",
            "episode=713/2500, total_reward=-95.8206, avg_reward=-93.3117, time=130328\n",
            "episode=714/2500, total_reward=-94.3019, avg_reward=-93.3015, time=130452\n",
            "episode=715/2500, total_reward=-92.5318, avg_reward=-93.2540, time=130575\n",
            "episode=716/2500, total_reward=-94.4488, avg_reward=-93.2734, time=130725\n",
            "episode=717/2500, total_reward=-100.6332, avg_reward=-93.6717, time=130818\n",
            "episode=718/2500, total_reward=-95.3500, avg_reward=-93.8506, time=130912\n",
            "episode=719/2500, total_reward=-93.6605, avg_reward=-93.8451, time=131030\n",
            "episode=720/2500, total_reward=-93.7799, avg_reward=-93.7812, time=131175\n",
            "episode=721/2500, total_reward=-93.6664, avg_reward=-93.7887, time=131344\n",
            "episode=722/2500, total_reward=-93.6415, avg_reward=-93.7362, time=131471\n",
            "episode=723/2500, total_reward=-95.7304, avg_reward=-93.8450, time=131620\n",
            "episode=724/2500, total_reward=-90.8225, avg_reward=-93.6934, time=131766\n",
            "episode=725/2500, total_reward=-93.9553, avg_reward=-93.8350, time=131852\n",
            "episode=726/2500, total_reward=-93.5249, avg_reward=-93.8243, time=131953\n",
            "episode=727/2500, total_reward=-92.3785, avg_reward=-93.8090, time=132083\n",
            "episode=728/2500, total_reward=-93.9559, avg_reward=-93.7974, time=132238\n",
            "episode=729/2500, total_reward=-95.9965, avg_reward=-94.0032, time=132368\n",
            "episode=730/2500, total_reward=-92.9397, avg_reward=-93.9717, time=132473\n",
            "episode=731/2500, total_reward=-92.4754, avg_reward=-93.9502, time=132591\n",
            "episode=732/2500, total_reward=-94.9545, avg_reward=-94.0365, time=132713\n",
            "episode=733/2500, total_reward=-92.8901, avg_reward=-94.0429, time=132848\n",
            "episode=734/2500, total_reward=-97.6321, avg_reward=-94.2220, time=132965\n",
            "episode=735/2500, total_reward=-92.5802, avg_reward=-94.3037, time=133069\n",
            "episode=736/2500, total_reward=-97.3293, avg_reward=-94.4922, time=133195\n",
            "episode=737/2500, total_reward=-92.4165, avg_reward=-94.4874, time=133346\n",
            "episode=738/2500, total_reward=-90.7346, avg_reward=-94.2064, time=133581\n",
            "episode=739/2500, total_reward=-93.4831, avg_reward=-94.1079, time=133700\n",
            "episode=740/2500, total_reward=-91.1635, avg_reward=-94.0720, time=133859\n",
            "episode=741/2500, total_reward=-94.0680, avg_reward=-94.0422, time=133952\n",
            "episode=742/2500, total_reward=-94.4840, avg_reward=-94.0662, time=134091\n",
            "episode=743/2500, total_reward=-97.0733, avg_reward=-94.0886, time=134279\n",
            "episode=744/2500, total_reward=-93.6257, avg_reward=-94.0739, time=134406\n",
            "episode=745/2500, total_reward=-92.0112, avg_reward=-94.0441, time=134504\n",
            "episode=746/2500, total_reward=-92.8423, avg_reward=-94.0075, time=134631\n",
            "episode=747/2500, total_reward=-94.3102, avg_reward=-93.9438, time=134724\n",
            "episode=748/2500, total_reward=-92.9958, avg_reward=-93.9518, time=134834\n",
            "episode=749/2500, total_reward=-93.1439, avg_reward=-93.8770, time=134961\n",
            "episode=750/2500, total_reward=-92.6784, avg_reward=-93.8537, time=135084\n",
            "episode=751/2500, total_reward=-96.6544, avg_reward=-94.0193, time=135192\n",
            "episode=752/2500, total_reward=-92.9738, avg_reward=-94.0427, time=135294\n",
            "episode=753/2500, total_reward=-93.4459, avg_reward=-93.9565, time=135407\n",
            "episode=754/2500, total_reward=-94.4567, avg_reward=-93.9731, time=135510\n",
            "episode=755/2500, total_reward=-89.3385, avg_reward=-93.8649, time=135658\n",
            "episode=756/2500, total_reward=-92.1062, avg_reward=-93.8424, time=135784\n",
            "episode=757/2500, total_reward=-94.0133, avg_reward=-93.7898, time=135883\n",
            "episode=758/2500, total_reward=-94.8068, avg_reward=-93.7964, time=135975\n",
            "episode=759/2500, total_reward=-93.2022, avg_reward=-93.7786, time=136100\n",
            "episode=760/2500, total_reward=-91.9710, avg_reward=-93.7697, time=136231\n",
            "episode=761/2500, total_reward=-92.3428, avg_reward=-93.7390, time=136370\n",
            "episode=762/2500, total_reward=-91.8602, avg_reward=-93.7440, time=136501\n",
            "episode=763/2500, total_reward=-92.9746, avg_reward=-93.6871, time=136626\n",
            "episode=764/2500, total_reward=-93.2608, avg_reward=-93.6663, time=136736\n",
            "episode=765/2500, total_reward=-91.9381, avg_reward=-93.6544, time=136850\n",
            "episode=766/2500, total_reward=-92.5920, avg_reward=-93.6173, time=136964\n",
            "episode=767/2500, total_reward=-91.5763, avg_reward=-93.4362, time=137074\n",
            "episode=768/2500, total_reward=-93.9017, avg_reward=-93.4072, time=137180\n",
            "episode=769/2500, total_reward=-94.7042, avg_reward=-93.4281, time=137291\n",
            "episode=770/2500, total_reward=-93.7770, avg_reward=-93.4280, time=137403\n",
            "episode=771/2500, total_reward=-93.6479, avg_reward=-93.4276, time=137512\n",
            "episode=772/2500, total_reward=-92.9983, avg_reward=-93.4148, time=137619\n",
            "episode=773/2500, total_reward=-90.7084, avg_reward=-93.3143, time=137750\n",
            "episode=774/2500, total_reward=-93.5344, avg_reward=-93.3686, time=137843\n",
            "episode=775/2500, total_reward=-91.2512, avg_reward=-93.3145, time=137955\n",
            "episode=776/2500, total_reward=-93.7482, avg_reward=-93.3190, time=138048\n",
            "episode=777/2500, total_reward=-92.4092, avg_reward=-93.3196, time=138161\n",
            "episode=778/2500, total_reward=-92.7296, avg_reward=-93.2950, time=138268\n",
            "episode=779/2500, total_reward=-95.5427, avg_reward=-93.2860, time=138409\n",
            "episode=780/2500, total_reward=-92.1645, avg_reward=-93.2705, time=138513\n",
            "episode=781/2500, total_reward=-93.7105, avg_reward=-93.2952, time=138614\n",
            "episode=782/2500, total_reward=-92.9475, avg_reward=-93.2550, time=138713\n",
            "episode=783/2500, total_reward=-91.3975, avg_reward=-93.2252, time=138877\n",
            "episode=784/2500, total_reward=-122.3404, avg_reward=-93.7193, time=138966\n",
            "episode=785/2500, total_reward=-100.1154, avg_reward=-93.8700, time=139128\n",
            "episode=786/2500, total_reward=-95.0094, avg_reward=-93.8236, time=139258\n",
            "episode=787/2500, total_reward=-91.8036, avg_reward=-93.8114, time=139384\n",
            "episode=788/2500, total_reward=-92.3204, avg_reward=-93.8431, time=139491\n",
            "episode=789/2500, total_reward=-92.0370, avg_reward=-93.8142, time=139640\n",
            "episode=790/2500, total_reward=-89.1405, avg_reward=-93.7737, time=139801\n",
            "episode=791/2500, total_reward=-94.6107, avg_reward=-93.7846, time=139980\n",
            "episode=792/2500, total_reward=-94.8661, avg_reward=-93.7922, time=140085\n",
            "episode=793/2500, total_reward=-89.4729, avg_reward=-93.6402, time=140206\n",
            "episode=794/2500, total_reward=-85.4771, avg_reward=-93.4772, time=140411\n",
            "episode=795/2500, total_reward=-93.5566, avg_reward=-93.5081, time=140538\n",
            "episode=796/2500, total_reward=-90.4344, avg_reward=-93.4600, time=140650\n",
            "episode=797/2500, total_reward=-90.6667, avg_reward=-93.3871, time=140774\n",
            "episode=798/2500, total_reward=-95.8538, avg_reward=-93.4443, time=140988\n",
            "episode=799/2500, total_reward=-90.1048, avg_reward=-93.3835, time=141104\n",
            "episode=800/2500, total_reward=-87.6723, avg_reward=-93.2834, time=141273\n",
            "episode=801/2500, total_reward=-92.1220, avg_reward=-93.1927, time=141367\n",
            "episode=802/2500, total_reward=-96.3772, avg_reward=-93.2608, time=141437\n",
            "episode=803/2500, total_reward=-95.4120, avg_reward=-93.3001, time=141564\n",
            "episode=804/2500, total_reward=-93.6992, avg_reward=-93.2850, time=141673\n",
            "episode=805/2500, total_reward=-86.3530, avg_reward=-93.2253, time=141873\n",
            "episode=806/2500, total_reward=-94.7813, avg_reward=-93.2788, time=141978\n",
            "episode=807/2500, total_reward=-94.2986, avg_reward=-93.2845, time=142074\n",
            "episode=808/2500, total_reward=-93.7505, avg_reward=-93.2633, time=142169\n",
            "episode=809/2500, total_reward=-90.9357, avg_reward=-93.2180, time=142282\n",
            "episode=810/2500, total_reward=-91.8227, avg_reward=-93.2150, time=142412\n",
            "episode=811/2500, total_reward=-91.7230, avg_reward=-93.2026, time=142575\n",
            "episode=812/2500, total_reward=-91.0898, avg_reward=-93.1872, time=142693\n",
            "episode=813/2500, total_reward=-93.0821, avg_reward=-93.1894, time=142809\n",
            "episode=814/2500, total_reward=-87.6018, avg_reward=-93.0762, time=142948\n",
            "episode=815/2500, total_reward=-87.9309, avg_reward=-92.9961, time=143108\n",
            "episode=816/2500, total_reward=-87.9762, avg_reward=-92.9037, time=143234\n",
            "episode=817/2500, total_reward=-93.6835, avg_reward=-92.9459, time=143361\n",
            "episode=818/2500, total_reward=-89.7396, avg_reward=-92.8626, time=143522\n",
            "episode=819/2500, total_reward=-84.9875, avg_reward=-92.6683, time=143737\n",
            "episode=820/2500, total_reward=-83.9375, avg_reward=-92.4715, time=143905\n",
            "episode=821/2500, total_reward=-90.4979, avg_reward=-92.4085, time=144060\n",
            "episode=822/2500, total_reward=-87.3672, avg_reward=-92.2959, time=144207\n",
            "episode=823/2500, total_reward=-94.0137, avg_reward=-92.3620, time=144295\n",
            "episode=824/2500, total_reward=-90.8567, avg_reward=-92.3084, time=144477\n",
            "episode=825/2500, total_reward=-88.2986, avg_reward=-92.2494, time=144694\n",
            "episode=826/2500, total_reward=-78.0954, avg_reward=-91.9363, time=144985\n",
            "episode=827/2500, total_reward=-76.6312, avg_reward=-91.6208, time=145246\n",
            "episode=828/2500, total_reward=-82.1620, avg_reward=-91.4094, time=145539\n",
            "episode=829/2500, total_reward=-85.2843, avg_reward=-91.2043, time=145719\n",
            "episode=830/2500, total_reward=-82.4973, avg_reward=-91.0109, time=145967\n",
            "episode=831/2500, total_reward=-84.8676, avg_reward=-90.8341, time=146271\n",
            "episode=832/2500, total_reward=-85.1713, avg_reward=-90.6785, time=146479\n",
            "episode=833/2500, total_reward=-85.3363, avg_reward=-90.5573, time=146655\n",
            "episode=834/2500, total_reward=-91.0789, avg_reward=-89.9321, time=146781\n",
            "episode=835/2500, total_reward=-93.9865, avg_reward=-89.8095, time=146869\n",
            "episode=836/2500, total_reward=-91.7430, avg_reward=-89.7442, time=146996\n",
            "episode=837/2500, total_reward=-90.6534, avg_reward=-89.7212, time=147130\n",
            "episode=838/2500, total_reward=-85.4828, avg_reward=-89.5844, time=147317\n",
            "episode=839/2500, total_reward=-87.9028, avg_reward=-89.5017, time=147539\n",
            "episode=840/2500, total_reward=-88.5419, avg_reward=-89.4898, time=147736\n",
            "episode=841/2500, total_reward=-92.9413, avg_reward=-89.4564, time=147948\n",
            "episode=842/2500, total_reward=-94.8507, avg_reward=-89.4561, time=148074\n",
            "episode=843/2500, total_reward=-84.5458, avg_reward=-89.3575, time=148283\n",
            "episode=844/2500, total_reward=-92.1274, avg_reward=-89.4905, time=148406\n",
            "episode=845/2500, total_reward=-85.6511, avg_reward=-89.3324, time=148592\n",
            "episode=846/2500, total_reward=-89.6456, avg_reward=-89.3166, time=148765\n",
            "episode=847/2500, total_reward=-90.9037, avg_reward=-89.3214, time=148949\n",
            "episode=848/2500, total_reward=-97.2477, avg_reward=-89.3493, time=149178\n",
            "episode=849/2500, total_reward=-89.8582, avg_reward=-89.3443, time=149355\n",
            "episode=850/2500, total_reward=-90.7442, avg_reward=-89.4058, time=149520\n",
            "episode=851/2500, total_reward=-90.5250, avg_reward=-89.3738, time=149670\n",
            "episode=852/2500, total_reward=-86.5507, avg_reward=-89.1773, time=150083\n",
            "episode=853/2500, total_reward=-79.4749, avg_reward=-88.8586, time=150362\n",
            "episode=854/2500, total_reward=-90.6637, avg_reward=-88.7978, time=150493\n",
            "episode=855/2500, total_reward=-81.9989, avg_reward=-88.7108, time=150800\n",
            "episode=856/2500, total_reward=-90.1620, avg_reward=-88.6184, time=150993\n",
            "episode=857/2500, total_reward=-92.6568, avg_reward=-88.5855, time=151131\n",
            "episode=858/2500, total_reward=-82.2036, avg_reward=-88.3546, time=151369\n",
            "episode=859/2500, total_reward=-93.9121, avg_reward=-88.4141, time=151462\n",
            "episode=860/2500, total_reward=-89.9916, avg_reward=-88.3775, time=151654\n",
            "episode=861/2500, total_reward=-89.8675, avg_reward=-88.3404, time=151853\n",
            "episode=862/2500, total_reward=-92.1068, avg_reward=-88.3607, time=152000\n",
            "episode=863/2500, total_reward=-74.9014, avg_reward=-87.9971, time=152755\n",
            "episode=864/2500, total_reward=-93.5643, avg_reward=-88.1164, time=152883\n",
            "episode=865/2500, total_reward=-84.2594, avg_reward=-88.0430, time=153218\n",
            "episode=866/2500, total_reward=-92.7697, avg_reward=-88.1388, time=153419\n",
            "episode=867/2500, total_reward=-63.9240, avg_reward=-87.5436, time=154210\n",
            "episode=868/2500, total_reward=-56.7145, avg_reward=-86.8831, time=154841\n",
            "episode=869/2500, total_reward=-8.5827, avg_reward=-85.3550, time=156251\n",
            "episode=870/2500, total_reward=-46.6056, avg_reward=-84.6084, time=157123\n",
            "episode=871/2500, total_reward=86.2728, avg_reward=-81.0730, time=158723\n",
            "episode=872/2500, total_reward=-46.0920, avg_reward=-80.2475, time=160174\n",
            "episode=873/2500, total_reward=22.9863, avg_reward=-77.9075, time=161774\n",
            "episode=874/2500, total_reward=55.5012, avg_reward=-74.9803, time=163374\n",
            "episode=875/2500, total_reward=73.7637, avg_reward=-71.7391, time=164974\n",
            "episode=876/2500, total_reward=78.9301, avg_reward=-68.5986, time=166574\n",
            "episode=877/2500, total_reward=114.5130, avg_reward=-64.7757, time=168174\n",
            "episode=878/2500, total_reward=-101.9075, avg_reward=-65.1706, time=168256\n",
            "episode=879/2500, total_reward=117.3792, avg_reward=-61.1173, time=169856\n",
            "episode=880/2500, total_reward=-77.5899, avg_reward=-61.0192, time=170641\n",
            "episode=881/2500, total_reward=-62.6284, avg_reward=-60.5744, time=171033\n",
            "episode=882/2500, total_reward=-113.3240, avg_reward=-61.1375, time=171334\n",
            "episode=883/2500, total_reward=83.5712, avg_reward=-57.7593, time=172934\n",
            "episode=884/2500, total_reward=-67.6141, avg_reward=-57.2900, time=173326\n",
            "episode=885/2500, total_reward=149.6467, avg_reward=-52.4173, time=174926\n",
            "episode=886/2500, total_reward=166.7123, avg_reward=-47.2482, time=176526\n",
            "episode=887/2500, total_reward=154.9964, avg_reward=-42.3352, time=178126\n",
            "episode=888/2500, total_reward=169.9542, avg_reward=-37.2265, time=179726\n",
            "episode=889/2500, total_reward=174.5487, avg_reward=-31.9775, time=181326\n",
            "episode=890/2500, total_reward=179.0701, avg_reward=-26.6252, time=182926\n",
            "episode=891/2500, total_reward=182.5180, avg_reward=-21.1160, time=184526\n",
            "episode=892/2500, total_reward=189.0035, avg_reward=-15.4390, time=186126\n",
            "episode=893/2500, total_reward=198.3397, avg_reward=-9.7812, time=187726\n",
            "episode=894/2500, total_reward=202.7401, avg_reward=-3.8839, time=189326\n",
            "episode=895/2500, total_reward=212.9441, avg_reward=2.0880, time=190926\n",
            "episode=896/2500, total_reward=212.6217, avg_reward=8.1334, time=192526\n",
            "episode=897/2500, total_reward=220.4955, avg_reward=14.3613, time=194126\n",
            "episode=898/2500, total_reward=228.3814, avg_reward=20.8739, time=195726\n",
            "episode=899/2500, total_reward=234.9249, avg_reward=27.3696, time=197326\n",
            "episode=900/2500, total_reward=233.6085, avg_reward=33.8566, time=198926\n",
            "episode=901/2500, total_reward=258.5026, avg_reward=40.8372, time=200517\n",
            "episode=902/2500, total_reward=262.6014, avg_reward=47.8202, time=202087\n",
            "episode=903/2500, total_reward=263.9725, avg_reward=54.6892, time=203608\n",
            "episode=904/2500, total_reward=261.9434, avg_reward=61.7413, time=205157\n",
            "episode=905/2500, total_reward=132.9358, avg_reward=66.0400, time=206553\n",
            "episode=906/2500, total_reward=266.6986, avg_reward=73.1772, time=207989\n",
            "episode=907/2500, total_reward=-42.1945, avg_reward=74.1865, time=208364\n",
            "episode=908/2500, total_reward=-9.0269, avg_reward=75.6500, time=208928\n",
            "episode=909/2500, total_reward=5.3913, avg_reward=77.6361, time=209532\n",
            "episode=910/2500, total_reward=270.8186, avg_reward=84.8523, time=210874\n",
            "episode=911/2500, total_reward=270.2982, avg_reward=92.0556, time=212226\n",
            "episode=912/2500, total_reward=268.7423, avg_reward=99.2726, time=213595\n",
            "episode=913/2500, total_reward=271.0755, avg_reward=106.1921, time=214978\n",
            "episode=914/2500, total_reward=14.6098, avg_reward=108.3556, time=215580\n",
            "episode=915/2500, total_reward=-96.5338, avg_reward=108.1101, time=215660\n",
            "episode=916/2500, total_reward=-31.2433, avg_reward=109.3406, time=216048\n",
            "episode=917/2500, total_reward=95.2626, avg_reward=112.5244, time=217083\n",
            "episode=918/2500, total_reward=156.9300, avg_reward=116.7973, time=218463\n",
            "episode=919/2500, total_reward=-1.8405, avg_reward=116.9321, time=219045\n",
            "episode=920/2500, total_reward=-87.5366, avg_reward=116.1135, time=219178\n",
            "episode=921/2500, total_reward=-74.6912, avg_reward=112.8942, time=219384\n",
            "episode=922/2500, total_reward=-108.5520, avg_reward=111.6450, time=219482\n",
            "episode=923/2500, total_reward=-99.0010, avg_reward=109.2053, time=219574\n",
            "episode=924/2500, total_reward=-8.2570, avg_reward=107.9301, time=220124\n",
            "episode=925/2500, total_reward=-94.0799, avg_reward=104.5732, time=220229\n",
            "episode=926/2500, total_reward=-98.5765, avg_reward=101.0231, time=220323\n",
            "episode=927/2500, total_reward=-93.5358, avg_reward=96.8621, time=220460\n",
            "episode=928/2500, total_reward=5.8349, avg_reward=99.0170, time=221072\n",
            "episode=929/2500, total_reward=-18.0415, avg_reward=96.3086, time=221606\n",
            "episode=930/2500, total_reward=270.4470, avg_reward=103.2693, time=223083\n",
            "episode=931/2500, total_reward=-85.9964, avg_reward=102.8019, time=223223\n",
            "episode=932/2500, total_reward=276.6970, avg_reward=110.6024, time=224647\n",
            "episode=933/2500, total_reward=272.1010, avg_reward=114.3729, time=226085\n",
            "episode=934/2500, total_reward=277.9925, avg_reward=121.2851, time=227433\n",
            "episode=935/2500, total_reward=-98.2297, avg_reward=116.3275, time=227548\n",
            "episode=936/2500, total_reward=277.6465, avg_reward=118.5462, time=228931\n",
            "episode=937/2500, total_reward=-118.7248, avg_reward=113.0718, time=229010\n",
            "episode=938/2500, total_reward=-138.9882, avg_reward=106.8930, time=229225\n",
            "episode=939/2500, total_reward=-153.4099, avg_reward=100.3338, time=229666\n",
            "episode=940/2500, total_reward=129.8247, avg_reward=99.3489, time=230805\n",
            "episode=941/2500, total_reward=-118.5868, avg_reward=93.3268, time=230882\n",
            "episode=942/2500, total_reward=-121.9664, avg_reward=87.1074, time=230956\n",
            "episode=943/2500, total_reward=-118.1584, avg_reward=80.7774, time=231015\n",
            "episode=944/2500, total_reward=-123.5983, avg_reward=74.2507, time=231089\n",
            "episode=945/2500, total_reward=-125.3720, avg_reward=67.4843, time=231193\n",
            "episode=946/2500, total_reward=-110.8614, avg_reward=61.0147, time=231243\n",
            "episode=947/2500, total_reward=-110.9649, avg_reward=54.3855, time=231292\n",
            "episode=948/2500, total_reward=-108.5193, avg_reward=47.6475, time=231339\n",
            "episode=949/2500, total_reward=-107.4656, avg_reward=40.7996, time=231388\n",
            "episode=950/2500, total_reward=-107.0388, avg_reward=33.9867, time=231435\n",
            "episode=951/2500, total_reward=-106.9335, avg_reward=26.6780, time=231482\n",
            "episode=952/2500, total_reward=-106.8634, avg_reward=19.2887, time=231527\n",
            "episode=953/2500, total_reward=-106.4210, avg_reward=11.8808, time=231573\n",
            "episode=954/2500, total_reward=-106.9595, avg_reward=4.5027, time=231617\n",
            "episode=955/2500, total_reward=279.8960, avg_reward=7.4420, time=232951\n",
            "episode=956/2500, total_reward=-127.8241, avg_reward=-0.4485, time=233108\n",
            "episode=957/2500, total_reward=-123.0536, avg_reward=-2.0657, time=233208\n",
            "episode=958/2500, total_reward=9.2598, avg_reward=-1.7000, time=233799\n",
            "episode=959/2500, total_reward=-123.2205, avg_reward=-4.2722, time=233884\n",
            "episode=960/2500, total_reward=-128.9575, avg_reward=-12.2677, time=234028\n",
            "episode=961/2500, total_reward=-117.5281, avg_reward=-20.0242, time=234088\n",
            "episode=962/2500, total_reward=-116.7418, avg_reward=-27.7339, time=234160\n",
            "episode=963/2500, total_reward=273.2596, avg_reward=-27.6902, time=235498\n",
            "episode=964/2500, total_reward=282.6412, avg_reward=-22.3296, time=236828\n",
            "episode=965/2500, total_reward=280.7235, avg_reward=-14.7845, time=238159\n",
            "episode=966/2500, total_reward=123.7244, avg_reward=-11.6851, time=239324\n",
            "episode=967/2500, total_reward=279.0534, avg_reward=-8.0093, time=240706\n",
            "episode=968/2500, total_reward=280.0838, avg_reward=-5.5462, time=242062\n",
            "episode=969/2500, total_reward=280.1322, avg_reward=0.0932, time=243410\n",
            "episode=970/2500, total_reward=281.3607, avg_reward=7.4712, time=244757\n",
            "episode=971/2500, total_reward=284.8119, avg_reward=14.6612, time=246042\n",
            "episode=972/2500, total_reward=284.3495, avg_reward=22.5193, time=247363\n",
            "episode=973/2500, total_reward=284.8520, avg_reward=30.1963, time=248637\n",
            "episode=974/2500, total_reward=285.9738, avg_reward=36.0810, time=249876\n",
            "episode=975/2500, total_reward=287.6801, avg_reward=43.7162, time=251071\n",
            "episode=976/2500, total_reward=289.3405, avg_reward=51.4745, time=252265\n",
            "episode=977/2500, total_reward=288.9238, avg_reward=59.1237, time=253451\n",
            "episode=978/2500, total_reward=287.4758, avg_reward=64.7565, time=254630\n",
            "episode=979/2500, total_reward=-32.6745, avg_reward=64.4638, time=254966\n",
            "episode=980/2500, total_reward=285.2236, avg_reward=64.7594, time=256134\n",
            "episode=981/2500, total_reward=289.0503, avg_reward=72.2603, time=257271\n",
            "episode=982/2500, total_reward=287.5103, avg_reward=72.4766, time=258438\n",
            "episode=983/2500, total_reward=288.2097, avg_reward=72.7988, time=259597\n",
            "episode=984/2500, total_reward=286.7078, avg_reward=72.9731, time=260788\n",
            "episode=985/2500, total_reward=-78.4041, avg_reward=73.3696, time=260945\n",
            "episode=986/2500, total_reward=42.7510, avg_reward=68.6717, time=261552\n",
            "episode=987/2500, total_reward=285.2714, avg_reward=76.7516, time=262752\n",
            "episode=988/2500, total_reward=288.8709, avg_reward=85.3088, time=263902\n",
            "episode=989/2500, total_reward=292.7819, avg_reward=94.2326, time=265025\n",
            "episode=990/2500, total_reward=293.3345, avg_reward=97.5028, time=266146\n",
            "episode=991/2500, total_reward=292.5971, avg_reward=105.7265, time=267262\n",
            "episode=992/2500, total_reward=296.2606, avg_reward=114.0910, time=268361\n",
            "episode=993/2500, total_reward=-106.7401, avg_reward=114.3194, time=268487\n",
            "episode=994/2500, total_reward=297.0606, avg_reward=122.7326, time=269531\n",
            "episode=995/2500, total_reward=9.0459, avg_reward=125.4209, time=269962\n",
            "episode=996/2500, total_reward=298.9691, avg_reward=133.6175, time=271000\n",
            "episode=997/2500, total_reward=29.1920, avg_reward=136.4207, time=271487\n",
            "episode=998/2500, total_reward=298.3586, avg_reward=144.5582, time=272546\n",
            "episode=999/2500, total_reward=298.8591, avg_reward=152.6847, time=273597\n",
            "episode=1000/2500, total_reward=38.9249, avg_reward=155.6040, time=274112\n",
            "episode=1001/2500, total_reward=298.3721, avg_reward=163.7101, time=275153\n",
            "episode=1002/2500, total_reward=300.4155, avg_reward=171.8557, time=276188\n",
            "episode=1003/2500, total_reward=-39.9046, avg_reward=173.1860, time=276452\n",
            "episode=1004/2500, total_reward=298.4172, avg_reward=181.2935, time=277504\n",
            "episode=1005/2500, total_reward=128.2152, avg_reward=178.2599, time=278350\n",
            "episode=1006/2500, total_reward=300.9373, avg_reward=186.8352, time=279348\n",
            "episode=1007/2500, total_reward=303.3355, avg_reward=195.3629, time=280339\n",
            "episode=1008/2500, total_reward=304.3174, avg_reward=201.2641, time=281334\n",
            "episode=1009/2500, total_reward=301.7271, avg_reward=209.7630, time=282323\n",
            "episode=1010/2500, total_reward=303.0683, avg_reward=218.4036, time=283291\n",
            "episode=1011/2500, total_reward=305.1794, avg_reward=226.8577, time=284241\n",
            "episode=1012/2500, total_reward=0.0903, avg_reward=229.1943, time=284602\n",
            "episode=1013/2500, total_reward=303.6417, avg_reward=229.8020, time=285500\n",
            "episode=1014/2500, total_reward=56.5970, avg_reward=225.2811, time=285983\n",
            "episode=1015/2500, total_reward=-4.6089, avg_reward=219.5745, time=286306\n",
            "episode=1016/2500, total_reward=4.7918, avg_reward=217.1958, time=286651\n",
            "episode=1017/2500, total_reward=88.4683, avg_reward=213.3841, time=287246\n",
            "episode=1018/2500, total_reward=305.5709, avg_reward=213.8938, time=288169\n",
            "episode=1019/2500, total_reward=304.4401, avg_reward=214.3800, time=289084\n",
            "episode=1020/2500, total_reward=-9.9557, avg_reward=208.5537, time=289416\n",
            "episode=1021/2500, total_reward=183.8244, avg_reward=206.5339, time=290303\n",
            "episode=1022/2500, total_reward=302.9820, avg_reward=206.9066, time=291221\n",
            "episode=1023/2500, total_reward=305.0765, avg_reward=207.3111, time=292168\n",
            "episode=1024/2500, total_reward=304.8617, avg_reward=207.6888, time=293099\n",
            "episode=1025/2500, total_reward=306.7385, avg_reward=208.0700, time=293971\n",
            "episode=1026/2500, total_reward=306.1000, avg_reward=208.4052, time=294853\n",
            "episode=1027/2500, total_reward=306.3102, avg_reward=208.7529, time=295741\n",
            "episode=1028/2500, total_reward=304.8194, avg_reward=209.0998, time=296615\n",
            "episode=1029/2500, total_reward=183.5797, avg_reward=213.4249, time=297483\n",
            "episode=1030/2500, total_reward=100.3414, avg_reward=209.7272, time=298118\n",
            "episode=1031/2500, total_reward=306.5215, avg_reward=210.0766, time=298973\n",
            "episode=1032/2500, total_reward=-8.8536, avg_reward=204.1494, time=299263\n",
            "episode=1033/2500, total_reward=306.4799, avg_reward=204.5148, time=300148\n",
            "episode=1034/2500, total_reward=303.7932, avg_reward=204.8565, time=301073\n",
            "episode=1035/2500, total_reward=307.7162, avg_reward=212.5789, time=301965\n",
            "episode=1036/2500, total_reward=306.6788, avg_reward=217.8574, time=302861\n",
            "episode=1037/2500, total_reward=48.0671, avg_reward=213.1134, time=303329\n",
            "episode=1038/2500, total_reward=306.9868, avg_reward=213.4757, time=304191\n",
            "episode=1039/2500, total_reward=309.9859, avg_reward=213.8198, time=305053\n",
            "episode=1040/2500, total_reward=309.9081, avg_reward=214.1512, time=305904\n",
            "episode=1041/2500, total_reward=190.3119, avg_reward=212.1055, time=306742\n",
            "episode=1042/2500, total_reward=310.1635, avg_reward=212.3836, time=307622\n",
            "episode=1043/2500, total_reward=308.8936, avg_reward=220.6963, time=308474\n",
            "episode=1044/2500, total_reward=309.0839, avg_reward=220.9367, time=309335\n",
            "episode=1045/2500, total_reward=308.0935, avg_reward=226.9177, time=310196\n",
            "episode=1046/2500, total_reward=308.4515, avg_reward=227.1073, time=311055\n",
            "episode=1047/2500, total_reward=309.2112, avg_reward=232.7077, time=311920\n",
            "episode=1048/2500, total_reward=311.4685, avg_reward=232.9699, time=312746\n",
            "episode=1049/2500, total_reward=309.3295, avg_reward=233.1793, time=313615\n",
            "episode=1050/2500, total_reward=310.2589, avg_reward=238.6060, time=314462\n",
            "episode=1051/2500, total_reward=309.7630, avg_reward=238.8338, time=315309\n",
            "episode=1052/2500, total_reward=309.2435, avg_reward=239.0104, time=316138\n",
            "episode=1053/2500, total_reward=309.6074, avg_reward=246.0006, time=316962\n",
            "episode=1054/2500, total_reward=310.6705, avg_reward=246.2457, time=317776\n",
            "episode=1055/2500, total_reward=-41.0054, avg_reward=242.8613, time=317984\n",
            "episode=1056/2500, total_reward=311.7724, avg_reward=243.0780, time=318798\n",
            "episode=1057/2500, total_reward=310.7342, avg_reward=243.2259, time=319611\n",
            "episode=1058/2500, total_reward=-45.5843, avg_reward=236.2279, time=319826\n",
            "episode=1059/2500, total_reward=307.9130, avg_reward=236.3516, time=320671\n",
            "episode=1060/2500, total_reward=313.0051, avg_reward=236.5504, time=321466\n",
            "episode=1061/2500, total_reward=312.9363, avg_reward=236.7055, time=322261\n",
            "episode=1062/2500, total_reward=-21.7491, avg_reward=236.2687, time=322513\n",
            "episode=1063/2500, total_reward=46.7648, avg_reward=231.1312, time=322917\n",
            "episode=1064/2500, total_reward=310.1680, avg_reward=236.2026, time=323733\n",
            "episode=1065/2500, total_reward=312.2087, avg_reward=242.5389, time=324536\n",
            "episode=1066/2500, total_reward=63.0512, avg_reward=243.7041, time=325004\n",
            "episode=1067/2500, total_reward=10.8685, avg_reward=242.1521, time=325349\n",
            "episode=1068/2500, total_reward=128.2967, avg_reward=238.6067, time=325943\n",
            "episode=1069/2500, total_reward=313.8952, avg_reward=238.7958, time=326743\n",
            "episode=1070/2500, total_reward=312.9465, avg_reward=245.2538, time=327550\n",
            "episode=1071/2500, total_reward=-52.4751, avg_reward=240.5278, time=327737\n",
            "episode=1072/2500, total_reward=313.4039, avg_reward=240.7362, time=328550\n",
            "episode=1073/2500, total_reward=307.3519, avg_reward=240.7818, time=329349\n",
            "episode=1074/2500, total_reward=313.0212, avg_reward=240.9449, time=330145\n",
            "episode=1075/2500, total_reward=-59.1403, avg_reward=233.6274, time=330310\n",
            "episode=1076/2500, total_reward=41.6773, avg_reward=228.3389, time=330715\n",
            "episode=1077/2500, total_reward=69.9583, avg_reward=223.6119, time=331187\n",
            "episode=1078/2500, total_reward=312.0785, avg_reward=223.7571, time=331985\n",
            "episode=1079/2500, total_reward=-97.8275, avg_reward=218.1289, time=332064\n",
            "episode=1080/2500, total_reward=-90.7569, avg_reward=214.3069, time=332153\n",
            "episode=1081/2500, total_reward=311.1715, avg_reward=214.3999, time=332966\n",
            "episode=1082/2500, total_reward=313.5724, avg_reward=220.8485, time=333754\n",
            "episode=1083/2500, total_reward=-96.9972, avg_reward=212.7789, time=333827\n",
            "episode=1084/2500, total_reward=-92.8849, avg_reward=204.8454, time=333914\n",
            "episode=1085/2500, total_reward=-93.8523, avg_reward=196.8140, time=333993\n",
            "episode=1086/2500, total_reward=47.7056, avg_reward=191.6345, time=334408\n",
            "episode=1087/2500, total_reward=313.6059, avg_reward=196.9453, time=335183\n",
            "episode=1088/2500, total_reward=185.0660, avg_reward=194.5069, time=335889\n",
            "episode=1089/2500, total_reward=38.6798, avg_reward=189.0808, time=336285\n",
            "episode=1090/2500, total_reward=312.7207, avg_reward=189.1370, time=337073\n",
            "episode=1091/2500, total_reward=314.1292, avg_reward=191.6134, time=337852\n",
            "episode=1092/2500, total_reward=61.0112, avg_reward=186.6303, time=338320\n",
            "episode=1093/2500, total_reward=314.0864, avg_reward=186.7342, time=339117\n",
            "episode=1094/2500, total_reward=-97.1442, avg_reward=178.6096, time=339205\n",
            "episode=1095/2500, total_reward=314.0678, avg_reward=178.7291, time=339998\n",
            "episode=1096/2500, total_reward=-93.7289, avg_reward=170.6855, time=340115\n",
            "episode=1097/2500, total_reward=-96.5888, avg_reward=162.5695, time=340224\n",
            "episode=1098/2500, total_reward=310.3076, avg_reward=162.5463, time=341051\n",
            "episode=1099/2500, total_reward=312.5060, avg_reward=162.6098, time=341854\n",
            "episode=1100/2500, total_reward=148.9738, avg_reward=159.3841, time=342506\n",
            "episode=1101/2500, total_reward=317.0005, avg_reward=159.5289, time=343284\n",
            "episode=1102/2500, total_reward=315.3987, avg_reward=159.6520, time=344093\n",
            "episode=1103/2500, total_reward=-89.7842, avg_reward=151.6641, time=344194\n",
            "episode=1104/2500, total_reward=315.6231, avg_reward=151.7632, time=344995\n",
            "episode=1105/2500, total_reward=314.1428, avg_reward=158.8661, time=345808\n",
            "episode=1106/2500, total_reward=152.5345, avg_reward=155.6814, time=346468\n",
            "episode=1107/2500, total_reward=172.3193, avg_reward=152.9131, time=347201\n",
            "episode=1108/2500, total_reward=318.0105, avg_reward=160.1850, time=347984\n",
            "episode=1109/2500, total_reward=194.6988, avg_reward=157.9207, time=348782\n",
            "episode=1110/2500, total_reward=-23.1199, avg_reward=151.1982, time=349029\n",
            "episode=1111/2500, total_reward=-49.5016, avg_reward=143.9494, time=349213\n",
            "episode=1112/2500, total_reward=3.9794, avg_reward=144.4640, time=349554\n",
            "episode=1113/2500, total_reward=71.4937, avg_reward=144.9586, time=350050\n",
            "episode=1114/2500, total_reward=316.4172, avg_reward=145.0836, time=350865\n",
            "episode=1115/2500, total_reward=316.6818, avg_reward=145.1730, time=351641\n",
            "episode=1116/2500, total_reward=-15.5147, avg_reward=143.6017, time=351946\n",
            "episode=1117/2500, total_reward=318.4929, avg_reward=149.7542, time=352741\n",
            "episode=1118/2500, total_reward=-76.5969, avg_reward=145.6563, time=352876\n",
            "episode=1119/2500, total_reward=156.3766, avg_reward=142.5060, time=353551\n",
            "episode=1120/2500, total_reward=319.5909, avg_reward=142.6388, time=354322\n",
            "episode=1121/2500, total_reward=320.9832, avg_reward=150.1080, time=355081\n",
            "episode=1122/2500, total_reward=316.6686, avg_reward=150.1733, time=355844\n",
            "episode=1123/2500, total_reward=-88.1340, avg_reward=142.2636, time=355944\n",
            "episode=1124/2500, total_reward=82.0328, avg_reward=137.6438, time=356420\n",
            "episode=1125/2500, total_reward=-96.7442, avg_reward=136.8917, time=356492\n",
            "episode=1126/2500, total_reward=79.6277, avg_reward=137.6507, time=356963\n",
            "episode=1127/2500, total_reward=-2.9618, avg_reward=136.1923, time=357259\n",
            "episode=1128/2500, total_reward=316.1229, avg_reward=136.2732, time=358035\n",
            "episode=1129/2500, total_reward=318.3755, avg_reward=144.5973, time=358795\n",
            "episode=1130/2500, total_reward=39.2862, avg_reward=147.1982, time=359192\n",
            "episode=1131/2500, total_reward=314.8586, avg_reward=147.2719, time=359986\n",
            "episode=1132/2500, total_reward=317.1870, avg_reward=147.3442, time=360753\n",
            "episode=1133/2500, total_reward=-16.3042, avg_reward=148.9580, time=361006\n",
            "episode=1134/2500, total_reward=154.4511, avg_reward=153.9048, time=361664\n",
            "episode=1135/2500, total_reward=-99.3028, avg_reward=153.7958, time=361733\n",
            "episode=1136/2500, total_reward=310.9444, avg_reward=159.0605, time=362578\n",
            "episode=1137/2500, total_reward=143.1767, avg_reward=155.6520, time=363208\n",
            "episode=1138/2500, total_reward=50.1166, avg_reward=152.9530, time=363621\n",
            "episode=1139/2500, total_reward=174.2110, avg_reward=155.6636, time=364302\n",
            "episode=1140/2500, total_reward=-62.0852, avg_reward=148.1675, time=364456\n",
            "episode=1141/2500, total_reward=320.0216, avg_reward=148.2853, time=365200\n",
            "episode=1142/2500, total_reward=167.6648, avg_reward=150.4184, time=365866\n",
            "episode=1143/2500, total_reward=317.5980, avg_reward=150.4886, time=366608\n",
            "episode=1144/2500, total_reward=318.4642, avg_reward=158.8008, time=367382\n",
            "episode=1145/2500, total_reward=114.4789, avg_reward=154.8090, time=367913\n",
            "episode=1146/2500, total_reward=320.7284, avg_reward=163.0982, time=368659\n",
            "episode=1147/2500, total_reward=17.3717, avg_reward=165.3774, time=368985\n",
            "episode=1148/2500, total_reward=320.2852, avg_reward=165.5769, time=369732\n",
            "episode=1149/2500, total_reward=320.2435, avg_reward=165.7317, time=370480\n",
            "episode=1150/2500, total_reward=105.6359, avg_reward=164.8649, time=370996\n",
            "episode=1151/2500, total_reward=320.3988, avg_reward=164.9329, time=371764\n",
            "episode=1152/2500, total_reward=318.3162, avg_reward=164.9912, time=372539\n",
            "episode=1153/2500, total_reward=319.9457, avg_reward=173.1858, time=373287\n",
            "episode=1154/2500, total_reward=320.5435, avg_reward=173.2842, time=374041\n",
            "episode=1155/2500, total_reward=319.3434, avg_reward=173.3882, time=374786\n",
            "episode=1156/2500, total_reward=321.3413, avg_reward=176.7644, time=375520\n",
            "episode=1157/2500, total_reward=320.3211, avg_reward=179.7244, time=376266\n",
            "episode=1158/2500, total_reward=321.9885, avg_reward=179.8040, time=377001\n",
            "episode=1159/2500, total_reward=320.6209, avg_reward=182.3224, time=377741\n",
            "episode=1160/2500, total_reward=320.6063, avg_reward=189.1969, time=378476\n",
            "episode=1161/2500, total_reward=321.5567, avg_reward=196.6181, time=379216\n",
            "episode=1162/2500, total_reward=80.7795, avg_reward=198.1541, time=379655\n",
            "episode=1163/2500, total_reward=319.5417, avg_reward=203.1151, time=380396\n",
            "episode=1164/2500, total_reward=7.5272, avg_reward=196.9373, time=380706\n",
            "episode=1165/2500, total_reward=320.8184, avg_reward=197.0200, time=381446\n",
            "episode=1166/2500, total_reward=320.7765, avg_reward=203.7458, time=382161\n",
            "episode=1167/2500, total_reward=319.6691, avg_reward=203.7694, time=382887\n",
            "episode=1168/2500, total_reward=322.2339, avg_reward=211.7460, time=383594\n",
            "episode=1169/2500, total_reward=320.8884, avg_reward=215.0362, time=384324\n",
            "episode=1170/2500, total_reward=320.9767, avg_reward=215.0639, time=385055\n",
            "episode=1171/2500, total_reward=90.1635, avg_reward=210.4475, time=385518\n",
            "episode=1172/2500, total_reward=322.4840, avg_reward=210.5638, time=386245\n",
            "episode=1173/2500, total_reward=322.4069, avg_reward=218.7746, time=386973\n",
            "episode=1174/2500, total_reward=322.5557, avg_reward=223.5851, time=387698\n",
            "episode=1175/2500, total_reward=321.9189, avg_reward=231.9584, time=388426\n",
            "episode=1176/2500, total_reward=317.8540, avg_reward=236.7229, time=389166\n",
            "episode=1177/2500, total_reward=324.3390, avg_reward=243.2689, time=389879\n",
            "episode=1178/2500, total_reward=324.4756, avg_reward=243.4360, time=390591\n",
            "episode=1179/2500, total_reward=322.5535, avg_reward=243.5195, time=391322\n",
            "episode=1180/2500, total_reward=192.1314, avg_reward=246.5764, time=391994\n",
            "episode=1181/2500, total_reward=51.2345, avg_reward=241.3039, time=392400\n",
            "episode=1182/2500, total_reward=325.1377, avg_reward=241.4630, time=393113\n",
            "episode=1183/2500, total_reward=322.7530, avg_reward=248.2441, time=393835\n",
            "episode=1184/2500, total_reward=-5.6526, avg_reward=245.0420, time=394116\n",
            "episode=1185/2500, total_reward=321.9686, avg_reward=253.4675, time=394841\n",
            "episode=1186/2500, total_reward=-57.8083, avg_reward=246.0924, time=395001\n",
            "episode=1187/2500, total_reward=163.8964, avg_reward=246.5068, time=395627\n",
            "episode=1188/2500, total_reward=-27.7077, avg_reward=244.9503, time=395858\n",
            "episode=1189/2500, total_reward=148.5328, avg_reward=244.4367, time=396440\n",
            "episode=1190/2500, total_reward=323.0800, avg_reward=252.1401, time=397143\n",
            "episode=1191/2500, total_reward=-110.6696, avg_reward=243.5262, time=397202\n",
            "episode=1192/2500, total_reward=319.4754, avg_reward=246.5624, time=397939\n",
            "episode=1193/2500, total_reward=74.4787, avg_reward=241.7001, time=398390\n",
            "episode=1194/2500, total_reward=321.8030, avg_reward=241.7668, time=399108\n",
            "episode=1195/2500, total_reward=323.0156, avg_reward=245.9376, time=399833\n",
            "episode=1196/2500, total_reward=60.5502, avg_reward=240.7340, time=400260\n",
            "episode=1197/2500, total_reward=80.4269, avg_reward=241.9951, time=400699\n",
            "episode=1198/2500, total_reward=321.8995, avg_reward=242.0274, time=401420\n",
            "episode=1199/2500, total_reward=50.5266, avg_reward=236.6331, time=401799\n",
            "episode=1200/2500, total_reward=163.8098, avg_reward=237.7965, time=402428\n",
            "episode=1201/2500, total_reward=322.9292, avg_reward=237.8471, time=403155\n",
            "episode=1202/2500, total_reward=321.3341, avg_reward=237.9075, time=403886\n",
            "episode=1203/2500, total_reward=321.5116, avg_reward=237.9388, time=404601\n",
            "episode=1204/2500, total_reward=322.8433, avg_reward=237.9848, time=405303\n",
            "episode=1205/2500, total_reward=321.0094, avg_reward=238.0181, time=406037\n",
            "episode=1206/2500, total_reward=96.5354, avg_reward=233.5220, time=406515\n",
            "episode=1207/2500, total_reward=-16.8377, avg_reward=226.7788, time=406762\n",
            "episode=1208/2500, total_reward=321.1691, avg_reward=226.7625, time=407471\n",
            "episode=1209/2500, total_reward=322.3285, avg_reward=226.7966, time=408169\n",
            "episode=1210/2500, total_reward=321.5299, avg_reward=226.8151, time=408880\n",
            "episode=1211/2500, total_reward=-5.2201, avg_reward=220.2795, time=409146\n",
            "episode=1212/2500, total_reward=-9.5617, avg_reward=218.4727, time=409406\n",
            "episode=1213/2500, total_reward=139.0504, avg_reward=214.8629, time=409970\n",
            "episode=1214/2500, total_reward=72.7608, avg_reward=216.1676, time=410397\n",
            "episode=1215/2500, total_reward=33.6225, avg_reward=210.4236, time=410738\n",
            "episode=1216/2500, total_reward=321.0076, avg_reward=210.4283, time=411470\n",
            "episode=1217/2500, total_reward=90.9900, avg_reward=205.8547, time=411928\n",
            "episode=1218/2500, total_reward=321.2443, avg_reward=205.8349, time=412638\n",
            "episode=1219/2500, total_reward=321.4312, avg_reward=205.8457, time=413329\n",
            "episode=1220/2500, total_reward=320.6735, avg_reward=205.8397, time=414040\n",
            "episode=1221/2500, total_reward=320.2238, avg_reward=210.4409, time=414741\n",
            "episode=1222/2500, total_reward=318.6348, avg_reward=210.3639, time=415462\n",
            "episode=1223/2500, total_reward=320.4674, avg_reward=210.3251, time=416181\n",
            "episode=1224/2500, total_reward=320.3941, avg_reward=210.2819, time=416898\n",
            "episode=1225/2500, total_reward=96.5122, avg_reward=205.7737, time=417364\n",
            "episode=1226/2500, total_reward=320.7741, avg_reward=205.8322, time=418072\n",
            "episode=1227/2500, total_reward=322.6485, avg_reward=205.7983, time=418767\n",
            "episode=1228/2500, total_reward=123.2622, avg_reward=201.7741, time=419314\n",
            "episode=1229/2500, total_reward=322.8309, avg_reward=201.7796, time=420020\n",
            "episode=1230/2500, total_reward=90.9835, avg_reward=199.7567, time=420493\n",
            "episode=1231/2500, total_reward=321.9566, avg_reward=205.1711, time=421191\n",
            "episode=1232/2500, total_reward=320.0205, avg_reward=205.0688, time=421896\n",
            "episode=1233/2500, total_reward=156.6982, avg_reward=201.7477, time=422484\n",
            "episode=1234/2500, total_reward=321.4698, avg_reward=208.2901, time=423181\n",
            "episode=1235/2500, total_reward=321.9706, avg_reward=208.2902, time=423883\n",
            "episode=1236/2500, total_reward=322.6163, avg_reward=215.8986, time=424573\n",
            "episode=1237/2500, total_reward=322.0376, avg_reward=219.0615, time=425264\n",
            "episode=1238/2500, total_reward=318.9957, avg_reward=225.9955, time=425979\n",
            "episode=1239/2500, total_reward=-34.7489, avg_reward=222.3299, time=426180\n",
            "episode=1240/2500, total_reward=319.8528, avg_reward=222.2654, time=426888\n",
            "episode=1241/2500, total_reward=319.6851, avg_reward=230.8724, time=427608\n",
            "episode=1242/2500, total_reward=321.5546, avg_reward=230.9140, time=428326\n",
            "episode=1243/2500, total_reward=315.1050, avg_reward=235.7266, time=429024\n",
            "episode=1244/2500, total_reward=322.6676, avg_reward=235.7438, time=429721\n",
            "episode=1245/2500, total_reward=323.4825, avg_reward=235.7532, time=430395\n",
            "episode=1246/2500, total_reward=319.9518, avg_reward=240.9412, time=431095\n",
            "episode=1247/2500, total_reward=321.8556, avg_reward=245.7698, time=431791\n",
            "episode=1248/2500, total_reward=50.9451, avg_reward=240.3507, time=432161\n",
            "episode=1249/2500, total_reward=11.0472, avg_reward=239.5611, time=432452\n",
            "episode=1250/2500, total_reward=38.6485, avg_reward=237.0579, time=432801\n",
            "episode=1251/2500, total_reward=322.4291, avg_reward=237.0479, time=433482\n",
            "episode=1252/2500, total_reward=320.2026, avg_reward=237.0253, time=434192\n",
            "episode=1253/2500, total_reward=318.4278, avg_reward=236.9636, time=434938\n",
            "episode=1254/2500, total_reward=-40.8433, avg_reward=229.6899, time=435140\n",
            "episode=1255/2500, total_reward=38.0917, avg_reward=224.0315, time=435489\n",
            "episode=1256/2500, total_reward=323.6745, avg_reward=228.5743, time=436170\n",
            "episode=1257/2500, total_reward=322.5499, avg_reward=235.3620, time=436865\n",
            "episode=1258/2500, total_reward=320.8735, avg_reward=235.3561, time=437563\n",
            "episode=1259/2500, total_reward=321.4343, avg_reward=235.3382, time=438267\n",
            "episode=1260/2500, total_reward=320.6113, avg_reward=235.3199, time=438966\n",
            "episode=1261/2500, total_reward=319.1828, avg_reward=241.8079, time=439683\n",
            "episode=1262/2500, total_reward=321.5337, avg_reward=248.4298, time=440375\n",
            "episode=1263/2500, total_reward=323.2752, avg_reward=252.1143, time=441056\n",
            "episode=1264/2500, total_reward=46.1389, avg_reward=251.5819, time=441416\n",
            "episode=1265/2500, total_reward=320.7044, avg_reward=257.3235, time=442110\n",
            "episode=1266/2500, total_reward=322.3640, avg_reward=257.3507, time=442779\n",
            "episode=1267/2500, total_reward=19.1742, avg_reward=255.9143, time=443095\n",
            "episode=1268/2500, total_reward=322.3890, avg_reward=255.9372, time=443783\n",
            "episode=1269/2500, total_reward=322.9781, avg_reward=255.9682, time=444490\n",
            "episode=1270/2500, total_reward=323.1946, avg_reward=256.0186, time=445179\n",
            "episode=1271/2500, total_reward=322.8473, avg_reward=256.0711, time=445854\n",
            "episode=1272/2500, total_reward=322.7127, avg_reward=256.1526, time=446541\n",
            "episode=1273/2500, total_reward=322.2017, avg_reward=256.1873, time=447231\n",
            "episode=1274/2500, total_reward=323.4163, avg_reward=256.2478, time=447912\n",
            "episode=1275/2500, total_reward=-15.0826, avg_reward=254.0159, time=448163\n",
            "episode=1276/2500, total_reward=323.8803, avg_reward=254.0780, time=448834\n",
            "episode=1277/2500, total_reward=173.0269, avg_reward=251.0855, time=449461\n",
            "episode=1278/2500, total_reward=-86.8724, avg_reward=246.8829, time=449553\n",
            "episode=1279/2500, total_reward=321.5563, avg_reward=246.8574, time=450259\n",
            "episode=1280/2500, total_reward=323.6199, avg_reward=251.5101, time=450937\n",
            "episode=1281/2500, total_reward=323.5599, avg_reward=251.5422, time=451614\n",
            "episode=1282/2500, total_reward=320.8725, avg_reward=251.5592, time=452282\n",
            "episode=1283/2500, total_reward=322.5542, avg_reward=254.8763, time=452992\n",
            "episode=1284/2500, total_reward=119.3959, avg_reward=250.8348, time=453498\n",
            "episode=1285/2500, total_reward=145.6590, avg_reward=247.3086, time=454026\n",
            "episode=1286/2500, total_reward=81.3725, avg_reward=242.4837, time=454458\n",
            "episode=1287/2500, total_reward=323.9906, avg_reward=242.5228, time=455140\n",
            "episode=1288/2500, total_reward=39.2279, avg_reward=236.9274, time=455474\n",
            "episode=1289/2500, total_reward=325.1954, avg_reward=244.1263, time=456156\n",
            "episode=1290/2500, total_reward=42.9203, avg_reward=238.5877, time=456489\n",
            "episode=1291/2500, total_reward=321.0749, avg_reward=238.6155, time=457200\n",
            "episode=1292/2500, total_reward=324.6828, avg_reward=238.6780, time=457874\n",
            "episode=1293/2500, total_reward=57.8381, avg_reward=233.5327, time=458252\n",
            "episode=1294/2500, total_reward=323.8801, avg_reward=233.5569, time=458936\n",
            "episode=1295/2500, total_reward=325.1265, avg_reward=233.5898, time=459605\n",
            "episode=1296/2500, total_reward=325.5225, avg_reward=233.7012, time=460270\n",
            "episode=1297/2500, total_reward=324.7540, avg_reward=233.7592, time=460942\n",
            "episode=1298/2500, total_reward=324.4132, avg_reward=239.2286, time=461630\n",
            "episode=1299/2500, total_reward=325.2793, avg_reward=245.5132, time=462299\n",
            "episode=1300/2500, total_reward=324.5888, avg_reward=251.2320, time=462971\n",
            "episode=1301/2500, total_reward=325.6741, avg_reward=251.2969, time=463641\n",
            "episode=1302/2500, total_reward=324.7124, avg_reward=251.3871, time=464316\n",
            "episode=1303/2500, total_reward=60.1132, avg_reward=246.2208, time=464695\n",
            "episode=1304/2500, total_reward=34.0129, avg_reward=247.7179, time=465023\n",
            "episode=1305/2500, total_reward=324.0435, avg_reward=253.4370, time=465696\n",
            "episode=1306/2500, total_reward=321.2283, avg_reward=253.3881, time=466406\n",
            "episode=1307/2500, total_reward=323.2810, avg_reward=253.4027, time=467096\n",
            "episode=1308/2500, total_reward=324.3320, avg_reward=253.4719, time=467773\n",
            "episode=1309/2500, total_reward=324.6124, avg_reward=253.5354, time=468438\n",
            "episode=1310/2500, total_reward=135.2033, avg_reward=249.8273, time=468960\n",
            "episode=1311/2500, total_reward=323.8406, avg_reward=249.9204, time=469631\n",
            "episode=1312/2500, total_reward=323.2827, avg_reward=249.9554, time=470309\n",
            "episode=1313/2500, total_reward=149.2968, avg_reward=246.4758, time=470866\n",
            "episode=1314/2500, total_reward=142.3768, avg_reward=248.4006, time=471412\n",
            "episode=1315/2500, total_reward=323.8896, avg_reward=248.4643, time=472090\n",
            "episode=1316/2500, total_reward=211.1617, avg_reward=246.2402, time=472753\n",
            "episode=1317/2500, total_reward=143.2370, avg_reward=248.7215, time=473299\n",
            "episode=1318/2500, total_reward=117.9306, avg_reward=244.6323, time=473783\n",
            "episode=1319/2500, total_reward=39.7350, avg_reward=238.9675, time=474120\n",
            "episode=1320/2500, total_reward=42.0009, avg_reward=233.3436, time=474456\n",
            "episode=1321/2500, total_reward=323.9996, avg_reward=233.3666, time=475115\n",
            "episode=1322/2500, total_reward=321.7468, avg_reward=233.3473, time=475799\n",
            "episode=1323/2500, total_reward=320.0711, avg_reward=233.3047, time=476509\n",
            "episode=1324/2500, total_reward=322.4845, avg_reward=233.2861, time=477182\n",
            "episode=1325/2500, total_reward=160.7379, avg_reward=236.8025, time=477754\n",
            "episode=1326/2500, total_reward=88.9775, avg_reward=232.1044, time=478179\n",
            "episode=1327/2500, total_reward=-32.7507, avg_reward=227.9889, time=478391\n",
            "episode=1328/2500, total_reward=124.6831, avg_reward=232.2200, time=478893\n",
            "episode=1329/2500, total_reward=73.5066, avg_reward=227.2590, time=479295\n",
            "episode=1330/2500, total_reward=320.5725, avg_reward=227.1980, time=479972\n",
            "episode=1331/2500, total_reward=117.3211, avg_reward=223.0733, time=480463\n",
            "episode=1332/2500, total_reward=322.1460, avg_reward=223.0987, time=481151\n",
            "episode=1333/2500, total_reward=-18.5508, avg_reward=216.2766, time=481375\n",
            "episode=1334/2500, total_reward=323.1353, avg_reward=220.3514, time=482040\n",
            "episode=1335/2500, total_reward=323.0123, avg_reward=223.8985, time=482719\n",
            "episode=1336/2500, total_reward=-30.2912, avg_reward=221.6652, time=482933\n",
            "episode=1337/2500, total_reward=323.0664, avg_reward=221.6467, time=483607\n",
            "episode=1338/2500, total_reward=149.3189, avg_reward=223.8486, time=484142\n",
            "episode=1339/2500, total_reward=323.7933, avg_reward=223.8205, time=484812\n",
            "episode=1340/2500, total_reward=23.0057, avg_reward=223.4222, time=485117\n",
            "episode=1341/2500, total_reward=97.3911, avg_reward=218.9485, time=485568\n",
            "episode=1342/2500, total_reward=322.2955, avg_reward=218.9008, time=486243\n",
            "episode=1343/2500, total_reward=45.1688, avg_reward=218.6474, time=486587\n",
            "episode=1344/2500, total_reward=322.7244, avg_reward=218.6243, time=487261\n",
            "episode=1345/2500, total_reward=321.1874, avg_reward=218.5455, time=487923\n",
            "episode=1346/2500, total_reward=324.7549, avg_reward=218.5302, time=488581\n",
            "episode=1347/2500, total_reward=319.7455, avg_reward=218.4300, time=489290\n",
            "episode=1348/2500, total_reward=178.8742, avg_reward=215.5192, time=489902\n",
            "episode=1349/2500, total_reward=-48.8093, avg_reward=208.0374, time=490084\n",
            "episode=1350/2500, total_reward=324.7501, avg_reward=208.0407, time=490739\n",
            "episode=1351/2500, total_reward=323.5676, avg_reward=207.9985, time=491395\n",
            "episode=1352/2500, total_reward=323.7354, avg_reward=207.9790, time=492058\n",
            "episode=1353/2500, total_reward=324.7361, avg_reward=213.2715, time=492711\n",
            "episode=1354/2500, total_reward=324.9950, avg_reward=219.0911, time=493364\n",
            "episode=1355/2500, total_reward=323.3440, avg_reward=219.0771, time=494036\n",
            "episode=1356/2500, total_reward=324.4690, avg_reward=219.1419, time=494691\n",
            "episode=1357/2500, total_reward=325.3021, avg_reward=219.1823, time=495341\n",
            "episode=1358/2500, total_reward=323.8530, avg_reward=219.1728, time=496010\n",
            "episode=1359/2500, total_reward=325.2354, avg_reward=219.1852, time=496665\n",
            "episode=1360/2500, total_reward=325.1833, avg_reward=222.9848, time=497314\n",
            "episode=1361/2500, total_reward=322.8910, avg_reward=222.9658, time=497980\n",
            "episode=1362/2500, total_reward=48.5984, avg_reward=217.4722, time=498318\n",
            "episode=1363/2500, total_reward=325.6681, avg_reward=220.9996, time=498966\n",
            "episode=1364/2500, total_reward=323.4118, avg_reward=224.6203, time=499632\n",
            "episode=1365/2500, total_reward=324.5093, avg_reward=224.6327, time=500282\n",
            "episode=1366/2500, total_reward=174.5995, avg_reward=223.9014, time=500884\n",
            "episode=1367/2500, total_reward=324.9585, avg_reward=227.5359, time=501536\n",
            "episode=1368/2500, total_reward=324.6326, avg_reward=231.6699, time=502193\n",
            "episode=1369/2500, total_reward=17.4708, avg_reward=231.2246, time=502488\n",
            "episode=1370/2500, total_reward=324.8660, avg_reward=236.8819, time=503140\n",
            "episode=1371/2500, total_reward=324.9494, avg_reward=236.9009, time=503794\n",
            "episode=1372/2500, total_reward=323.0352, avg_reward=236.9267, time=504455\n",
            "episode=1373/2500, total_reward=323.4379, avg_reward=236.9940, time=505116\n",
            "episode=1374/2500, total_reward=324.6455, avg_reward=237.0372, time=505768\n",
            "episode=1375/2500, total_reward=326.4018, avg_reward=240.3505, time=506428\n",
            "episode=1376/2500, total_reward=324.8443, avg_reward=245.0678, time=507096\n",
            "episode=1377/2500, total_reward=94.4371, avg_reward=247.6116, time=507551\n",
            "episode=1378/2500, total_reward=323.8330, avg_reward=251.5946, time=508220\n",
            "episode=1379/2500, total_reward=325.3367, avg_reward=256.6312, time=508876\n",
            "episode=1380/2500, total_reward=-16.2920, avg_reward=249.8939, time=509105\n",
            "episode=1381/2500, total_reward=324.7615, avg_reward=254.0427, time=509764\n",
            "episode=1382/2500, total_reward=175.1011, avg_reward=251.1018, time=510334\n",
            "episode=1383/2500, total_reward=-49.5771, avg_reward=250.4813, time=510535\n",
            "episode=1384/2500, total_reward=43.0321, avg_reward=244.8792, time=510871\n",
            "episode=1385/2500, total_reward=-86.2565, avg_reward=236.6939, time=510973\n",
            "episode=1386/2500, total_reward=-50.0908, avg_reward=236.2979, time=511151\n",
            "episode=1387/2500, total_reward=-83.9343, avg_reward=228.1579, time=511248\n",
            "episode=1388/2500, total_reward=324.1116, avg_reward=231.6537, time=511928\n",
            "episode=1389/2500, total_reward=65.0460, avg_reward=226.4788, time=512334\n",
            "episode=1390/2500, total_reward=148.2996, avg_reward=228.9846, time=512898\n",
            "episode=1391/2500, total_reward=70.5302, avg_reward=228.4474, time=513301\n",
            "episode=1392/2500, total_reward=-90.0972, avg_reward=220.1996, time=513393\n",
            "episode=1393/2500, total_reward=321.4911, avg_reward=225.7260, time=514077\n",
            "episode=1394/2500, total_reward=323.3685, avg_reward=225.7389, time=514755\n",
            "episode=1395/2500, total_reward=322.0216, avg_reward=225.7556, time=515457\n",
            "episode=1396/2500, total_reward=325.0142, avg_reward=225.7608, time=516114\n",
            "episode=1397/2500, total_reward=324.9783, avg_reward=225.8654, time=516785\n",
            "episode=1398/2500, total_reward=323.5616, avg_reward=228.7592, time=517481\n",
            "episode=1399/2500, total_reward=324.9009, avg_reward=236.2334, time=518152\n",
            "episode=1400/2500, total_reward=325.5057, avg_reward=236.2485, time=518823\n",
            "episode=1401/2500, total_reward=325.9480, avg_reward=236.2961, time=519494\n",
            "episode=1402/2500, total_reward=326.0365, avg_reward=236.3421, time=520165\n",
            "episode=1403/2500, total_reward=326.5105, avg_reward=236.3776, time=520826\n",
            "episode=1404/2500, total_reward=325.6576, avg_reward=236.3908, time=521486\n",
            "episode=1405/2500, total_reward=326.2725, avg_reward=236.4494, time=522145\n",
            "episode=1406/2500, total_reward=325.9078, avg_reward=236.4782, time=522810\n",
            "episode=1407/2500, total_reward=326.1218, avg_reward=236.4946, time=523474\n",
            "episode=1408/2500, total_reward=174.4754, avg_reward=233.5070, time=524052\n",
            "episode=1409/2500, total_reward=325.2470, avg_reward=233.5073, time=524718\n",
            "episode=1410/2500, total_reward=326.7529, avg_reward=233.5387, time=525385\n",
            "episode=1411/2500, total_reward=326.5276, avg_reward=233.6114, time=526049\n",
            "episode=1412/2500, total_reward=324.2938, avg_reward=239.1253, time=526717\n",
            "episode=1413/2500, total_reward=-24.0114, avg_reward=232.1317, time=526939\n",
            "episode=1414/2500, total_reward=88.6924, avg_reward=227.4373, time=527372\n",
            "episode=1415/2500, total_reward=325.6416, avg_reward=227.4600, time=528025\n",
            "episode=1416/2500, total_reward=326.1177, avg_reward=230.4903, time=528686\n",
            "episode=1417/2500, total_reward=206.2348, avg_reward=228.1159, time=529334\n",
            "episode=1418/2500, total_reward=-63.9803, avg_reward=220.3436, time=529489\n",
            "episode=1419/2500, total_reward=325.4726, avg_reward=226.5036, time=530151\n",
            "episode=1420/2500, total_reward=325.3753, avg_reward=226.5138, time=530811\n",
            "episode=1421/2500, total_reward=109.1401, avg_reward=222.1976, time=531275\n",
            "episode=1422/2500, total_reward=180.1574, avg_reward=219.3401, time=531890\n",
            "episode=1423/2500, total_reward=321.3837, avg_reward=219.2990, time=532569\n",
            "episode=1424/2500, total_reward=-52.4464, avg_reward=211.7572, time=532726\n",
            "episode=1425/2500, total_reward=40.5050, avg_reward=206.0392, time=533085\n",
            "episode=1426/2500, total_reward=98.3061, avg_reward=201.5085, time=533531\n",
            "episode=1427/2500, total_reward=-3.7604, avg_reward=199.5445, time=533787\n",
            "episode=1428/2500, total_reward=89.8438, avg_reward=194.8647, time=534222\n",
            "episode=1429/2500, total_reward=100.6440, avg_reward=190.3709, time=534670\n",
            "episode=1430/2500, total_reward=322.0089, avg_reward=197.1369, time=535345\n",
            "episode=1431/2500, total_reward=323.6012, avg_reward=197.1137, time=536009\n",
            "episode=1432/2500, total_reward=322.5313, avg_reward=200.0623, time=536694\n",
            "episode=1433/2500, total_reward=-54.8526, avg_reward=199.9568, time=536909\n",
            "episode=1434/2500, total_reward=-46.8819, avg_reward=198.1585, time=537147\n",
            "episode=1435/2500, total_reward=17.8269, avg_reward=200.2402, time=537496\n",
            "episode=1436/2500, total_reward=-13.1724, avg_reward=200.9785, time=537751\n",
            "episode=1437/2500, total_reward=176.7725, avg_reward=206.1927, time=538395\n",
            "episode=1438/2500, total_reward=38.0532, avg_reward=200.4715, time=538722\n",
            "episode=1439/2500, total_reward=149.2455, avg_reward=202.1555, time=539310\n",
            "episode=1440/2500, total_reward=322.4846, avg_reward=205.6392, time=539995\n",
            "episode=1441/2500, total_reward=322.7116, avg_reward=210.6828, time=540682\n",
            "episode=1442/2500, total_reward=323.6458, avg_reward=218.9577, time=541350\n",
            "episode=1443/2500, total_reward=323.4365, avg_reward=218.9966, time=542015\n",
            "episode=1444/2500, total_reward=324.2208, avg_reward=219.0136, time=542667\n",
            "episode=1445/2500, total_reward=322.6780, avg_reward=219.0268, time=543337\n",
            "episode=1446/2500, total_reward=321.1522, avg_reward=218.9495, time=544021\n",
            "episode=1447/2500, total_reward=323.7750, avg_reward=218.9255, time=544677\n",
            "episode=1448/2500, total_reward=323.8170, avg_reward=218.9306, time=545344\n",
            "episode=1449/2500, total_reward=324.4527, avg_reward=218.9216, time=546009\n",
            "episode=1450/2500, total_reward=322.3455, avg_reward=218.8584, time=546685\n",
            "episode=1451/2500, total_reward=321.9580, avg_reward=218.7786, time=547364\n",
            "episode=1452/2500, total_reward=22.9539, avg_reward=212.7169, time=547677\n",
            "episode=1453/2500, total_reward=323.0076, avg_reward=212.6469, time=548341\n",
            "episode=1454/2500, total_reward=-25.6873, avg_reward=205.6200, time=548573\n",
            "episode=1455/2500, total_reward=322.9312, avg_reward=205.5532, time=549252\n",
            "episode=1456/2500, total_reward=-93.0661, avg_reward=197.1737, time=549331\n",
            "episode=1457/2500, total_reward=323.8989, avg_reward=197.1292, time=549988\n",
            "episode=1458/2500, total_reward=322.7554, avg_reward=200.0948, time=550668\n",
            "episode=1459/2500, total_reward=322.3574, avg_reward=200.0370, time=551355\n",
            "episode=1460/2500, total_reward=4.5377, avg_reward=193.5927, time=551636\n",
            "episode=1461/2500, total_reward=323.8418, avg_reward=193.5390, time=552300\n",
            "episode=1462/2500, total_reward=322.7995, avg_reward=193.5091, time=552978\n",
            "episode=1463/2500, total_reward=163.6566, avg_reward=197.2625, time=553558\n",
            "episode=1464/2500, total_reward=321.4241, avg_reward=201.9171, time=554254\n",
            "episode=1465/2500, total_reward=324.3301, avg_reward=201.8909, time=554922\n",
            "episode=1466/2500, total_reward=59.1496, avg_reward=196.5515, time=555294\n",
            "episode=1467/2500, total_reward=325.1170, avg_reward=198.9292, time=555945\n",
            "episode=1468/2500, total_reward=323.8316, avg_reward=206.6854, time=556593\n",
            "episode=1469/2500, total_reward=324.0339, avg_reward=206.6566, time=557252\n",
            "episode=1470/2500, total_reward=322.6649, avg_reward=206.6024, time=557927\n",
            "episode=1471/2500, total_reward=324.6236, avg_reward=210.9121, time=558593\n",
            "episode=1472/2500, total_reward=323.9463, avg_reward=213.7879, time=559253\n",
            "episode=1473/2500, total_reward=322.8648, avg_reward=213.8175, time=559926\n",
            "episode=1474/2500, total_reward=322.4883, avg_reward=221.3162, time=560597\n",
            "episode=1475/2500, total_reward=322.5768, avg_reward=226.9576, time=561275\n",
            "episode=1476/2500, total_reward=121.2864, avg_reward=227.4172, time=561780\n",
            "episode=1477/2500, total_reward=323.6324, avg_reward=233.9651, time=562447\n",
            "episode=1478/2500, total_reward=53.2250, avg_reward=233.2327, time=562824\n",
            "episode=1479/2500, total_reward=204.3913, avg_reward=235.3077, time=563485\n",
            "episode=1480/2500, total_reward=324.4394, avg_reward=235.3563, time=564146\n",
            "episode=1481/2500, total_reward=323.2083, avg_reward=235.3484, time=564815\n",
            "episode=1482/2500, total_reward=325.7293, avg_reward=235.4124, time=565456\n",
            "episode=1483/2500, total_reward=173.9204, avg_reward=239.9878, time=566035\n",
            "episode=1484/2500, total_reward=324.5082, avg_reward=247.4156, time=566691\n",
            "episode=1485/2500, total_reward=324.1733, avg_reward=253.5426, time=567348\n",
            "episode=1486/2500, total_reward=324.3252, avg_reward=260.2925, time=568012\n",
            "episode=1487/2500, total_reward=319.8410, avg_reward=263.1539, time=568689\n",
            "episode=1488/2500, total_reward=324.5933, avg_reward=268.8847, time=569343\n",
            "episode=1489/2500, total_reward=324.8717, avg_reward=272.3972, time=569999\n",
            "episode=1490/2500, total_reward=-22.1628, avg_reward=265.5043, time=570225\n",
            "episode=1491/2500, total_reward=324.6482, avg_reward=265.5430, time=570872\n",
            "episode=1492/2500, total_reward=324.6687, avg_reward=265.5634, time=571532\n",
            "episode=1493/2500, total_reward=325.4507, avg_reward=265.6037, time=572176\n",
            "episode=1494/2500, total_reward=323.3720, avg_reward=265.5868, time=572833\n",
            "episode=1495/2500, total_reward=324.3423, avg_reward=265.6200, time=573482\n",
            "episode=1496/2500, total_reward=325.0616, avg_reward=265.6982, time=574131\n",
            "episode=1497/2500, total_reward=324.2642, avg_reward=265.7080, time=574782\n",
            "episode=1498/2500, total_reward=149.4307, avg_reward=262.2203, time=575301\n",
            "episode=1499/2500, total_reward=324.6461, avg_reward=262.2242, time=575944\n",
            "episode=1500/2500, total_reward=324.7533, avg_reward=262.2723, time=576592\n",
            "episode=1501/2500, total_reward=323.9690, avg_reward=262.3125, time=577257\n",
            "episode=1502/2500, total_reward=-89.2344, avg_reward=260.0688, time=577386\n",
            "episode=1503/2500, total_reward=324.0315, avg_reward=260.0892, time=578045\n",
            "episode=1504/2500, total_reward=323.2554, avg_reward=267.0681, time=578718\n",
            "episode=1505/2500, total_reward=-0.9681, avg_reward=260.5901, time=578979\n",
            "episode=1506/2500, total_reward=323.6494, avg_reward=268.9244, time=579629\n",
            "episode=1507/2500, total_reward=323.3118, avg_reward=268.9127, time=580289\n",
            "episode=1508/2500, total_reward=323.7230, avg_reward=268.9320, time=580956\n",
            "episode=1509/2500, total_reward=325.3319, avg_reward=268.9915, time=581599\n",
            "episode=1510/2500, total_reward=324.8440, avg_reward=275.3976, time=582237\n",
            "episode=1511/2500, total_reward=323.3152, avg_reward=275.3871, time=582900\n",
            "episode=1512/2500, total_reward=323.6676, avg_reward=275.4045, time=583546\n",
            "episode=1513/2500, total_reward=323.8478, avg_reward=278.6083, time=584214\n",
            "episode=1514/2500, total_reward=323.9243, avg_reward=278.6583, time=584872\n",
            "episode=1515/2500, total_reward=7.7387, avg_reward=272.3265, time=585148\n",
            "episode=1516/2500, total_reward=324.9642, avg_reward=277.6428, time=585801\n",
            "episode=1517/2500, total_reward=324.8912, avg_reward=277.6383, time=586458\n",
            "episode=1518/2500, total_reward=324.7903, avg_reward=277.6574, time=587099\n",
            "episode=1519/2500, total_reward=325.0487, avg_reward=277.6777, time=587747\n",
            "episode=1520/2500, total_reward=325.5092, avg_reward=277.7346, time=588389\n",
            "episode=1521/2500, total_reward=-95.2683, avg_reward=269.3368, time=588464\n",
            "episode=1522/2500, total_reward=325.3938, avg_reward=269.3657, time=589117\n",
            "episode=1523/2500, total_reward=326.9729, avg_reward=269.4479, time=589753\n",
            "episode=1524/2500, total_reward=325.1902, avg_reward=269.5019, time=590400\n",
            "episode=1525/2500, total_reward=323.7952, avg_reward=269.5263, time=591064\n",
            "episode=1526/2500, total_reward=325.3983, avg_reward=273.6085, time=591707\n",
            "episode=1527/2500, total_reward=319.4793, avg_reward=273.5255, time=592352\n",
            "episode=1528/2500, total_reward=325.1451, avg_reward=278.9639, time=592997\n",
            "episode=1529/2500, total_reward=321.5748, avg_reward=281.3075, time=593678\n",
            "episode=1530/2500, total_reward=169.0122, avg_reward=278.1990, time=594239\n",
            "episode=1531/2500, total_reward=90.9148, avg_reward=273.5531, time=594665\n",
            "episode=1532/2500, total_reward=324.2472, avg_reward=273.5235, time=595319\n",
            "episode=1533/2500, total_reward=326.4762, avg_reward=276.5746, time=595960\n",
            "episode=1534/2500, total_reward=326.0606, avg_reward=276.6057, time=596605\n",
            "episode=1535/2500, total_reward=140.9972, avg_reward=272.9421, time=597119\n",
            "episode=1536/2500, total_reward=325.4007, avg_reward=272.9636, time=597766\n",
            "episode=1537/2500, total_reward=150.9778, avg_reward=269.5864, time=598317\n",
            "episode=1538/2500, total_reward=324.1852, avg_reward=269.5782, time=598973\n",
            "episode=1539/2500, total_reward=14.9736, avg_reward=263.3803, time=599265\n",
            "episode=1540/2500, total_reward=327.5388, avg_reward=270.3743, time=599901\n",
            "episode=1541/2500, total_reward=326.3510, avg_reward=270.4083, time=600543\n",
            "episode=1542/2500, total_reward=327.3593, avg_reward=270.4622, time=601188\n",
            "episode=1543/2500, total_reward=327.3320, avg_reward=270.4998, time=601828\n",
            "episode=1544/2500, total_reward=327.1753, avg_reward=270.5758, time=602469\n",
            "episode=1545/2500, total_reward=327.8671, avg_reward=270.6463, time=603109\n",
            "episode=1546/2500, total_reward=327.0822, avg_reward=270.6868, time=603760\n",
            "episode=1547/2500, total_reward=327.2998, avg_reward=270.7475, time=604399\n",
            "episode=1548/2500, total_reward=326.9463, avg_reward=274.2978, time=605038\n",
            "episode=1549/2500, total_reward=325.0845, avg_reward=274.3065, time=605680\n",
            "episode=1550/2500, total_reward=326.4347, avg_reward=274.3402, time=606318\n",
            "episode=1551/2500, total_reward=325.5832, avg_reward=274.3725, time=606974\n",
            "episode=1552/2500, total_reward=323.0240, avg_reward=282.6176, time=607652\n",
            "episode=1553/2500, total_reward=325.6151, avg_reward=282.6493, time=608290\n",
            "episode=1554/2500, total_reward=324.2861, avg_reward=282.6699, time=608935\n",
            "episode=1555/2500, total_reward=325.9001, avg_reward=289.2073, time=609576\n",
            "episode=1556/2500, total_reward=326.6546, avg_reward=289.2674, time=610210\n",
            "episode=1557/2500, total_reward=325.2288, avg_reward=289.3057, time=610853\n",
            "episode=1558/2500, total_reward=325.7235, avg_reward=289.3457, time=611498\n",
            "episode=1559/2500, total_reward=325.6560, avg_reward=289.3522, time=612146\n",
            "episode=1560/2500, total_reward=326.0547, avg_reward=289.3764, time=612786\n",
            "episode=1561/2500, total_reward=326.3594, avg_reward=289.4373, time=613430\n",
            "episode=1562/2500, total_reward=326.4213, avg_reward=289.4924, time=614070\n",
            "episode=1563/2500, total_reward=327.0722, avg_reward=289.5569, time=614716\n",
            "episode=1564/2500, total_reward=326.1186, avg_reward=289.6008, time=615373\n",
            "episode=1565/2500, total_reward=326.5090, avg_reward=295.9762, time=616007\n",
            "episode=1566/2500, total_reward=326.9550, avg_reward=296.0160, time=616646\n",
            "episode=1567/2500, total_reward=327.1909, avg_reward=296.0620, time=617294\n",
            "episode=1568/2500, total_reward=326.1977, avg_reward=296.0901, time=617934\n",
            "episode=1569/2500, total_reward=327.6673, avg_reward=296.1425, time=618576\n",
            "episode=1570/2500, total_reward=327.3861, avg_reward=296.1800, time=619221\n",
            "episode=1571/2500, total_reward=327.4693, avg_reward=304.6348, time=619864\n",
            "Solved at 1571 episode!\n",
            "Average reward = 304 \n",
            "End Training \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKtHBWRELUqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_reward(reward, avg_reward, path):\n",
        "    \"\"\"\n",
        "        Plot figure for data.\n",
        "\n",
        "        Args:\n",
        "            data (list:float): List of input data.\n",
        "            x_label (str): Name for x label.\n",
        "            y_label (str): Name for y label.\n",
        "            title (str): Name for title.\n",
        "            path (str): Path to store plot.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(0, len(reward)), reward, label=\"Reward\")\n",
        "    plt.plot(np.arange(0, len(avg_reward)), avg_reward, label=\"Avg Reward\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Reward\")\n",
        "    plt.title(\"Training Process\")\n",
        "    plt.savefig(path)\n",
        "    plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej8pbHbNLacQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "786286ea-cf9a-4b3e-c5ce-d39e813bf6bc"
      },
      "source": [
        "# plot the training curve\n",
        "plot_reward(total_reward_history, avg_reward_history, \"./train_process.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDxK7DnWLdA6",
        "colab_type": "text"
      },
      "source": [
        "### 6. play with trained Twin-Delayed DDPG agent\n",
        "\n",
        "- After training, the simulation videos are saved in folder \"./after_train\", and the result looks like the following:\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ChienTeLee/td3_bipedal_walker/raw/master/doc/after_train.gif\" width=\"50%\" height=\"50%\"> \n",
        "</p>\n",
        "\n",
        "- We can see that the Bipedal Walker is able to walk to the end of the terrain, and the average reward is around +300 points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcMSbpXQL6WG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "302773fc-47b4-48e8-d4d5-ac1e8884d855"
      },
      "source": [
        "env = gym.make(\"BipedalWalker-v3\")\n",
        "env = wrappers.Monitor(env, \"./after_train\", force=True, video_callable=lambda episode: (episode+1)>0)\n",
        "total_reward_history = []\n",
        "\n",
        "# play 5 trials with greedy move\n",
        "for episode in range(5):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = 0\n",
        "\n",
        "    while not done:\n",
        "        action = td3_agent.choose_greedy_action(state)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "    total_reward_history.append(total_reward)\n",
        "\n",
        "avg_reward = np.mean(total_reward_history)\n",
        "print(\"Average reward after training = {}\".format(avg_reward))\n",
        "print (\"End Playing\")\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average reward after training = 328.0723454205537\n",
            "End Playing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz4RioanL62W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_path = \"./after_train\"\n",
        "play_video(video_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUV1a0INL640",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84c33c8f-0747-4255-8272-6201c59616c4"
      },
      "source": [
        "#save result to zip file\n",
        "!zip -r output.zip ./before_train ./during_train ./after_train train_process.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: before_train/ (stored 0%)\n",
            "  adding: before_train/openaigym.manifest.0.123.manifest.json (deflated 71%)\n",
            "  adding: before_train/openaigym.video.0.123.video000003.meta.json (deflated 60%)\n",
            "  adding: before_train/openaigym.episode_batch.0.123.stats.json (deflated 43%)\n",
            "  adding: before_train/openaigym.video.0.123.video000000.mp4 (deflated 6%)\n",
            "  adding: before_train/openaigym.video.0.123.video000002.mp4 (deflated 3%)\n",
            "  adding: before_train/openaigym.video.0.123.video000004.meta.json (deflated 60%)\n",
            "  adding: before_train/openaigym.video.0.123.video000001.meta.json (deflated 60%)\n",
            "  adding: before_train/openaigym.video.0.123.video000004.mp4 (deflated 3%)\n",
            "  adding: before_train/openaigym.video.0.123.video000001.mp4 (deflated 5%)\n",
            "  adding: before_train/openaigym.video.0.123.video000002.meta.json (deflated 60%)\n",
            "  adding: before_train/openaigym.video.0.123.video000000.meta.json (deflated 60%)\n",
            "  adding: before_train/openaigym.video.0.123.video000003.mp4 (deflated 4%)\n",
            "  adding: during_train/ (stored 0%)\n",
            "  adding: during_train/openaigym.video.1.123.video001149.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001049.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000549.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000874.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001024.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000449.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000349.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000199.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000349.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000449.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000499.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000874.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000599.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000974.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000799.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001099.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video001149.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000549.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001424.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000249.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000824.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.episode_batch.1.123.stats.json (deflated 63%)\n",
            "  adding: during_train/openaigym.video.1.123.video001374.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000174.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000224.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001074.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000424.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000724.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001174.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001424.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001499.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000924.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video001374.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001274.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001474.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000624.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000324.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001349.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000124.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000699.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000724.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001549.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000574.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001299.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000674.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000974.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001324.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000099.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000199.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000399.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001349.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000299.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000924.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001299.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000099.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000049.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000074.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001274.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000949.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000774.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000524.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000124.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000899.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video001199.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000299.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000474.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001449.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video001074.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000024.mp4 (deflated 9%)\n",
            "  adding: during_train/openaigym.video.1.123.video000674.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000849.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001399.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000774.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001224.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video001524.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.manifest.1.123.manifest.json (deflated 92%)\n",
            "  adding: during_train/openaigym.video.1.123.video001099.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001449.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001199.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000999.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001474.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000599.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000374.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000374.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000574.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000649.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000474.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001124.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001024.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000824.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000274.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000074.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000749.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video001124.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000049.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000324.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000274.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000799.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000399.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000024.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000224.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000699.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000649.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000249.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000949.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001399.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000149.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000749.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001324.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001524.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000149.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000999.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000499.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000174.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001224.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001049.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001499.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001249.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video000524.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000424.mp4 (deflated 8%)\n",
            "  adding: during_train/openaigym.video.1.123.video001174.mp4 (deflated 3%)\n",
            "  adding: during_train/openaigym.video.1.123.video001549.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video000849.mp4 (deflated 4%)\n",
            "  adding: during_train/openaigym.video.1.123.video000624.mp4 (deflated 5%)\n",
            "  adding: during_train/openaigym.video.1.123.video000899.meta.json (deflated 60%)\n",
            "  adding: during_train/openaigym.video.1.123.video001249.meta.json (deflated 60%)\n",
            "  adding: after_train/ (stored 0%)\n",
            "  adding: after_train/openaigym.video.2.123.video000000.mp4 (deflated 3%)\n",
            "  adding: after_train/openaigym.manifest.2.123.manifest.json (deflated 71%)\n",
            "  adding: after_train/openaigym.video.2.123.video000002.mp4 (deflated 3%)\n",
            "  adding: after_train/openaigym.episode_batch.2.123.stats.json (deflated 44%)\n",
            "  adding: after_train/openaigym.video.2.123.video000004.meta.json (deflated 60%)\n",
            "  adding: after_train/openaigym.video.2.123.video000003.mp4 (deflated 3%)\n",
            "  adding: after_train/openaigym.video.2.123.video000000.meta.json (deflated 60%)\n",
            "  adding: after_train/openaigym.video.2.123.video000002.meta.json (deflated 60%)\n",
            "  adding: after_train/openaigym.video.2.123.video000004.mp4 (deflated 4%)\n",
            "  adding: after_train/openaigym.video.2.123.video000001.meta.json (deflated 60%)\n",
            "  adding: after_train/openaigym.video.2.123.video000001.mp4 (deflated 3%)\n",
            "  adding: after_train/openaigym.video.2.123.video000003.meta.json (deflated 60%)\n",
            "  adding: train_process.png (deflated 2%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}